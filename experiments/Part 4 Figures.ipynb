{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45773e86-ab4f-42f0-b5c2-eb9893e550ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "\n",
    "from evaluation import *\n",
    "from data_loader import *\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05f179a2-7dd0-4b64-a41b-36d53d61dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\n",
    "    \"DQN\": 'darkorange',\n",
    "    \"REINFORCE\": 'forestgreen',\n",
    "    \"CMA\": 'cyan',\n",
    "    \"ODT\": 'blueviolet'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b193092f-542b-4de6-8757-68dc5cdfca57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for experiments 6090 to 6107\n"
     ]
    }
   ],
   "source": [
    "starting_exp = 4180\n",
    "ending_exp = 4188\n",
    "save_processed_data = True\n",
    "exp_lists_preformatted = [\n",
    "    '4000_4017.csv', '4018_4035.csv', '5000_5017.csv', '5018_5035.csv', '6000_6017.csv', '6018_6035.csv', # DQN\n",
    "    '4036_4053.csv', '4054_4071.csv', '5036_5053.csv', '5054_5071.csv', '6036_6053.csv', '6054_6071.csv', # REINFORCE\n",
    "    '4072_4089.csv', '4090_4107.csv', '5072_5089.csv', '5090_5107.csv', '6072_6089.csv', '6090_6107.csv', # CMA\n",
    "    '4108_4125.csv', '4126_4143.csv', '5108_5125.csv', '5126_5143.csv', '6108_6125.csv', '6126_6143.csv', # ODT 1\n",
    "    '4144_4161.csv', '4162_4179.csv', '5144_5161.csv', '5162_5179.csv', '6144_6161.csv', '6162_6179.csv' # ODT 2\n",
    "] # Existing formatted datasets\n",
    "# exp_lists_preformatted = [\n",
    "#     '4000_4179.csv', '5000_5179.csv', '6000_6179.csv'\n",
    "# ] # Existing formatted datasets\n",
    "#exp_lists_preformatted = []\n",
    "\n",
    "# TODO: REMOVE THIS!!\n",
    "index = 17 # 13, 15, 16 cause errors\n",
    "starting_exp = int(exp_lists_preformatted[index].split(\"_\")[0])\n",
    "ending_exp = int(exp_lists_preformatted[index].split(\"_\")[1].split('.')[0])\n",
    "\n",
    "exp_lists_preformatted = []\n",
    "\n",
    "print(f\"Running for experiments {starting_exp} to {ending_exp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "047648a7-4749-4142-a7ee-134f4b48ec94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment 6090 does not have matching aggregation level\n",
      "Experiment 6091 does not have matching aggregation level\n",
      "Experiment 6092 does not have matching aggregation level\n",
      "Loading ../../../../storage_1/metrics/Exp_6093/train/metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_6094/train/metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_6095/train/metrics.csv\n",
      "Experiment 6096 does not have matching aggregation level\n",
      "Experiment 6097 does not have matching aggregation level\n",
      "Experiment 6098 does not have matching aggregation level\n",
      "Experiment 6099 does not have matching aggregation level\n",
      "Experiment 6100 does not have matching aggregation level\n",
      "Experiment 6101 does not have matching aggregation level\n",
      "Loading ../../../../storage_1/metrics/Exp_6102/train/metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_6103/train/metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_6104/train/metrics.csv\n",
      "Experiment 6105 does not have matching aggregation level\n",
      "Experiment 6106 does not have matching aggregation level\n",
      "Experiment 6107 does not have matching aggregation level\n"
     ]
    }
   ],
   "source": [
    "load_agent = True\n",
    "load_station = True\n",
    "\n",
    "target_agg_count = 10\n",
    "target_reward_type = 'greedy'\n",
    "\n",
    "exp_agent_data = []\n",
    "exp_station_data = []\n",
    "\n",
    "experiments = range(starting_exp, ending_exp + 1)\n",
    "\n",
    "def load_episode_from_csv(filepath, columns=None, target_ep=999, target_agg=9, chunksize=100_000):\n",
    "    filtered_chunks = []\n",
    "    for chunk in pd.read_csv(filepath, usecols=columns, chunksize=chunksize):\n",
    "        sel = (chunk['episode'] == target_ep) & (chunk['aggregation'] == target_agg)\n",
    "        if sel.any():\n",
    "            filtered_chunks.append(chunk.loc[sel])\n",
    "    if filtered_chunks:\n",
    "        return pd.concat(filtered_chunks, ignore_index=True)\n",
    "    else:\n",
    "        return pd.DataFrame(columns=columns or [])\n",
    "\n",
    "\n",
    "if len(exp_lists_preformatted) == 0:\n",
    "    for ind, exp_num in enumerate(experiments):\n",
    "        config_fname = f'./Exp_{exp_num}/config.yaml'\n",
    "        \n",
    "        c = load_config_file(config_fname)\n",
    "        nn_c = c['nn_hyperparameters']\n",
    "        federated_c = c['federated_learning_settings']\n",
    "        algo_c = c['algorithm_settings']\n",
    "        env_c = c['environment_settings']\n",
    "        \n",
    "        if federated_c['aggregation_count'] != target_agg_count:\n",
    "            print(f\"Experiment {exp_num} does not have matching aggregation level\")\n",
    "            continue\n",
    "\n",
    "        rtype = 'communal' if nn_c['average_rewards_when_training'] else 'greedy'\n",
    "        if rtype != target_reward_type:\n",
    "            print(f\"Experiment {exp_num} does not have matching reward type\")\n",
    "            continue\n",
    "        \n",
    "        seed = env_c['seed']\n",
    "        algorithm_dm = algo_c['algorithm']\n",
    "        \n",
    "        d_base = f\"../../../../storage_1/metrics/Exp_{exp_num}\"\n",
    "        if not os.path.exists(d_base):\n",
    "            d_base = f\"../metrics/Exp_{exp_num}\"\n",
    "        base_path = f\"{d_base}/train/metrics\"\n",
    "\n",
    "        print(f'Loading {base_path}.csv')\n",
    "        # --- AGENT METRICS ---\n",
    "        if load_agent:\n",
    "            cols = [\n",
    "                'episode', 'timestep', 'done', 'zone', \n",
    "                'aggregation', 'reward', 'agent_index',\n",
    "                'distance', 'average_battery'\n",
    "            ]\n",
    "            agent_data = load_episode_from_csv(\n",
    "                f'{base_path}_agent_metrics.csv',\n",
    "                columns=cols\n",
    "            )\n",
    "            if agent_data.empty:\n",
    "                print(f\"No agent data for ep=10000 in Exp {exp_num}\")\n",
    "            else:\n",
    "                agent_data['seed'] = seed\n",
    "                agent_data['exp_num'] = exp_num\n",
    "                agent_data['algorithm'] = algorithm_dm\n",
    "                agent_data['season'] = env_c['season']\n",
    "                exp_agent_data.append(agent_data)\n",
    "\n",
    "        # --- STATION METRICS ---\n",
    "        if load_station:\n",
    "            cols = [\n",
    "                'episode', 'timestep', 'done', 'zone',\n",
    "                'aggregation', 'station_index', 'traffic'\n",
    "            ]\n",
    "            station_data = load_episode_from_csv(\n",
    "                f'{base_path}_station_metrics.csv',\n",
    "                columns=cols\n",
    "            )\n",
    "            if station_data.empty:\n",
    "                print(f\"No station data for ep=10000 in Exp {exp_num}\")\n",
    "            else:\n",
    "                station_data['seed'] = seed\n",
    "                station_data['exp_num'] = exp_num\n",
    "                station_data['algorithm'] = algorithm_dm\n",
    "                station_data['season'] = env_c['season']\n",
    "                exp_station_data.append(station_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c374987-9920-4ebe-903a-4383fff87814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cumulating data\n",
      "Recalculating episode\n"
     ]
    }
   ],
   "source": [
    "if len(exp_lists_preformatted) == 0:\n",
    "    # Convert data to DataFrame for easier manipulation\n",
    "    if load_agent:\n",
    "        df_agent = pd.concat(exp_agent_data, ignore_index=True)\n",
    "\n",
    "        cumulative_agent_df = (\n",
    "            df_agent\n",
    "            .groupby(\n",
    "                ['episode', 'zone', 'aggregation', 'agent_index', 'seed', 'exp_num', 'algorithm', 'season']\n",
    "            )[['distance', 'average_battery', 'reward']]\n",
    "            .sum()\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        # Rename the 'reward' column to 'cumulative_reward' for clarity\n",
    "        cumulative_agent_df.rename(columns={'average_battery': 'battery_used'}, inplace=True)\n",
    "        cumulative_agent_df.rename(columns={'distance': 'distance_traveled'}, inplace=True)\n",
    "        \n",
    "        cumulative_agent_df['episode'] = cumulative_agent_df['aggregation'] * (10000/target_agg_count) + cumulative_agent_df['episode']\n",
    "    \n",
    "    if load_station:\n",
    "        df_station = pd.concat(exp_station_data, ignore_index=True)\n",
    "    \n",
    "        print('Cumulating data')    \n",
    "        cumulative_station_df = (\n",
    "            df_station\n",
    "            .groupby(\n",
    "                ['episode', 'zone', 'aggregation', 'station_index', 'seed', 'exp_num', 'algorithm', 'season']\n",
    "            )[['traffic']]\n",
    "            .max()\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        print('Recalculating episode')    \n",
    "        # Get recalculated episodes using (aggregation number * episodes per aggregation) + episode number\n",
    "        cumulative_station_df['episode'] = cumulative_station_df['aggregation'] * (10000/target_agg_count)  + cumulative_station_df['episode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0607a2a7-5aae-4016-af67-095245cdc777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to ../../../../storage_1/metrics/formatted_experiment_data/part_4//agent_6090_6107.csv\n",
      "Data successfully saved to ../../../../storage_1/metrics/formatted_experiment_data/part_4//station_6090_6107.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the file path with starting_exp and ending_exp variables\n",
    "file_path_for_processed_data = f'../../../../storage_1/metrics/formatted_experiment_data/part_4/'\n",
    "\n",
    "if len(exp_lists_preformatted) == 0:\n",
    "\n",
    "    # Get the data for the last episode only\n",
    "    if load_agent:\n",
    "        cumulative_agent_df = cumulative_agent_df[cumulative_agent_df['episode'] == cumulative_agent_df['episode'].max()]\n",
    "    \n",
    "    if load_station:\n",
    "        cumulative_station_df = cumulative_station_df[cumulative_station_df['episode'] == cumulative_station_df['episode'].max()]\n",
    "\n",
    "    \n",
    "    if save_processed_data:\n",
    "        if not os.path.exists(file_path_for_processed_data):\n",
    "            os.makedirs(file_path_for_processed_data)\n",
    "        \n",
    "        # Save the DataFrame to a CSV file\n",
    "        if load_agent:\n",
    "            cumulative_agent_df.to_csv(f\"{file_path_for_processed_data}/agent_{starting_exp}_{ending_exp}.csv\", index=False)\n",
    "            print(f\"Data successfully saved to {file_path_for_processed_data}/agent_{starting_exp}_{ending_exp}.csv\")\n",
    "\n",
    "        if load_station:\n",
    "            cumulative_station_df.to_csv(f\"{file_path_for_processed_data}/station_{starting_exp}_{ending_exp}.csv\", index=False)\n",
    "            print(f\"Data successfully saved to {file_path_for_processed_data}/station_{starting_exp}_{ending_exp}.csv\")\n",
    "\n",
    "if len(exp_lists_preformatted) > 0:\n",
    "    if load_agent:\n",
    "        agent_dataframes = []\n",
    "        \n",
    "        # Load and combine datasets\n",
    "        for existing_set in exp_lists_preformatted:\n",
    "            loaded_dataset = pd.read_csv(f\"{file_path_for_processed_data}/agent_{existing_set}\")\n",
    "            # Combine datasets\n",
    "            agent_dataframes.append(loaded_dataset)\n",
    "    \n",
    "        cumulative_agent_df = pd.concat(agent_dataframes, ignore_index=True)\n",
    "\n",
    "    if load_station:\n",
    "        station_dataframes = []\n",
    "        \n",
    "        # Load and combine datasets\n",
    "        for existing_set in exp_lists_preformatted:\n",
    "            loaded_dataset = pd.read_csv(f\"{file_path_for_processed_data}/station_{existing_set}\")\n",
    "            # Combine datasets\n",
    "            station_dataframes.append(loaded_dataset)\n",
    "    \n",
    "        cumulative_station_df = pd.concat(station_dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6f1bac0-1dcf-4daf-b986-efb58314357a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Algorithm: CMA =====\n",
      "\tAverage Distance Travelled: 36.92\n",
      "\tDistance Travelled Std Dev: 1.33\n",
      "\t--\n",
      "\tAverage Battery Used (kWh): 22269.95\n",
      "\tBattery Used Std Dev (kWh): 3020.35\n",
      "\t--\n",
      "\tAverage Reward: -72.91\n",
      "\tReward Std Dev: 5.40\n",
      "\t--\n",
      "\tMax Traffic: 24.00\n",
      "\n",
      "\n",
      "\n",
      "Algorotim: CMA - Season: autumn             - Avg. Energy 21585.36 - Std. Energy 2961.28\n",
      "Algorotim: CMA - Season: summer             - Avg. Energy 22954.54 - Std. Energy 2923.24\n"
     ]
    }
   ],
   "source": [
    "if load_agent:\n",
    "    algos = cumulative_agent_df['algorithm'].unique()\n",
    "if load_station:\n",
    "    algos = cumulative_station_df['algorithm'].unique()\n",
    "\n",
    "for algo in algos:\n",
    "    print(f\"===== Algorithm: {algo} =====\")\n",
    "\n",
    "    if load_agent:\n",
    "        agent_d = cumulative_agent_df[cumulative_agent_df['algorithm'] == algo]\n",
    "        print(f\"\\tAverage Distance Travelled: {agent_d['distance_traveled'].mean():.2f}\")\n",
    "        print(f\"\\tDistance Travelled Std Dev: {agent_d['distance_traveled'].std():.2f}\")\n",
    "        print(f\"\\t--\")\n",
    "        print(f\"\\tAverage Battery Used (kWh): {agent_d['battery_used'].mean():.2f}\")\n",
    "        print(f\"\\tBattery Used Std Dev (kWh): {agent_d['battery_used'].std():.2f}\")\n",
    "        print(f\"\\t--\")\n",
    "        print(f\"\\tAverage Reward: {agent_d['reward'].mean():.2f}\")\n",
    "        print(f\"\\tReward Std Dev: {agent_d['reward'].std():.2f}\")\n",
    "        print(f\"\\t--\")\n",
    "    if load_station:\n",
    "        station_d = cumulative_station_df[cumulative_station_df['algorithm'] == algo]\n",
    "        print(f\"\\tMax Traffic: {station_d['traffic'].max():.2f}\")\n",
    "        #print(f\"\\tTraffic Std Dev: {station_d['traffic'].std():.2f}\")\n",
    "\n",
    "if load_agent:\n",
    "    print(\"\\n\\n\")\n",
    "    for season in cumulative_agent_df['season'].unique():\n",
    "        season_data = cumulative_agent_df[cumulative_agent_df['season'] == season]\n",
    "        \n",
    "        for algo in season_data['algorithm'].unique():\n",
    "            algo_data = season_data[season_data['algorithm'] == algo]\n",
    "    \n",
    "            avg_energy_used = algo_data['battery_used'].mean()\n",
    "            std_energy_used = algo_data['battery_used'].std()\n",
    "    \n",
    "            print(f\"Algorotim: {algo} - Season: {season} \\\n",
    "            - Avg. Energy {avg_energy_used:.2f} - Std. Energy {std_energy_used:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
