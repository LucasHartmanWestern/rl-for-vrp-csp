{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45773e86-ab4f-42f0-b5c2-eb9893e550ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "\n",
    "from evaluation import *\n",
    "from data_loader import *\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "047648a7-4749-4142-a7ee-134f4b48ec94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../../../../storage_1/metrics/Exp_108/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_108/train/metrics_station_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_109/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_109/train/metrics_station_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_110/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_110/train/metrics_station_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_111/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_111/train/metrics_station_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_112/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_112/train/metrics_station_metrics.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './Exp_113/config.yaml'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m exp_num \u001b[38;5;129;01min\u001b[39;00m experiments:\n\u001b[1;32m      8\u001b[0m     config_fname \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./Exp_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexp_num\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/config.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m---> 10\u001b[0m     c \u001b[38;5;241m=\u001b[39m \u001b[43mload_config_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig_fname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     nn_c \u001b[38;5;241m=\u001b[39m c[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnn_hyperparameters\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     12\u001b[0m     federated_c \u001b[38;5;241m=\u001b[39m c[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfederated_learning_settings\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/rl-for-vrp-csp(git)/data_loader.py:87\u001b[0m, in \u001b[0;36mload_config_file\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_config_file\u001b[39m(fname\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;66;03m# Created by Santiago 26/04/2024\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;124;03m    Helper method to load the configuration parameters from yaml file first the default yaml file is\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;124;03m    loaded and the upadted with the new most updated configuration yaml file given by fname.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     84\u001b[0m \n\u001b[1;32m     85\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m config:\n\u001b[1;32m     88\u001b[0m         parameters \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(config)\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parameters\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Exp_113/config.yaml'"
     ]
    }
   ],
   "source": [
    "experiments = range(108, 118)\n",
    "\n",
    "exp_agent_data = []\n",
    "exp_station_data = []\n",
    "\n",
    "\n",
    "for exp_num in experiments:\n",
    "    config_fname = f'./Exp_{exp_num}/config.yaml'\n",
    "    \n",
    "    c = load_config_file(config_fname)\n",
    "    nn_c = c['nn_hyperparameters']\n",
    "    federated_c = c['federated_learning_settings']\n",
    "    algo_c = c['algorithm_settings']\n",
    "    env_c = c['environment_settings']\n",
    "    eval_c = c['eval_config']\n",
    "\n",
    "    ev_info = []\n",
    "\n",
    "    seed = env_c['seed']\n",
    "\n",
    "    algorithm_dm = algo_c['algorithm']\n",
    "    \n",
    "    def load_from_json_with_error_handling(filepath, columns_specific):\n",
    "        try:\n",
    "            return read_csv_data(filepath, columns=columns_specific)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON from {filepath}: {e.msg} at line {e.lineno}, column {e.colno}\")\n",
    "            return None  # Handle the error and return None or an empty object\n",
    "    \n",
    "    \n",
    "    d_base = f\"../../../../storage_1/metrics/Exp_{exp_num}\"\n",
    "    \n",
    "    if not os.path.exists(d_base):\n",
    "        d_base = f\"../metrics/Exp_{exp_num}\"\n",
    "            \n",
    "    base_path = f\"{d_base}/train/metrics\"\n",
    "\n",
    "    print(f'Loading {base_path}_agent_metrics.csv')\n",
    "    agent_data = load_from_json_with_error_handling(f'{base_path}_agent_metrics.csv', ['episode', 'timestep', 'done', 'zone', 'aggregation', 'agent_index', 'car_model', 'reward', 'distance', 'average_battery'])\n",
    "\n",
    "    print(f'Loading {base_path}_station_metrics.csv')\n",
    "    station_data = load_from_json_with_error_handling(f'{base_path}_station_metrics.csv', ['episode', 'timestep', 'done', 'zone', 'aggregation', 'station_index', 'traffic'])\n",
    "\n",
    "    agent_data['seed'] = seed\n",
    "    agent_data['exp_num'] = exp_num\n",
    "    agent_data['algorithm'] = algorithm_dm\n",
    "    agent_data['season'] = env_c['season']\n",
    "\n",
    "    station_data['seed'] = seed\n",
    "    station_data['exp_num'] = exp_num\n",
    "    station_data['algorithm'] = algorithm_dm\n",
    "    station_data['season'] = env_c['season']\n",
    "\n",
    "    exp_agent_data.append(agent_data)\n",
    "    exp_station_data.append(station_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c374987-9920-4ebe-903a-4383fff87814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert data to DataFrame for easier manipulation\n",
    "df_agent = pd.concat(exp_agent_data, ignore_index=True)\n",
    "df_station = pd.concat(exp_station_data, ignore_index=True)\n",
    "\n",
    "# Scale timestep rewards by timestep index (uncomment this for reward v2)\n",
    "#df['reward'] = df['reward'] / (df['timestep'] + 1)\n",
    "\n",
    "# Only show a single timestep\n",
    "#df = df[df['timestep'] == 0]\n",
    "\n",
    "cumulative_agent_df = (\n",
    "    df_agent\n",
    "    .groupby(\n",
    "        ['episode', 'zone', 'aggregation', 'agent_index', 'seed', 'exp_num', 'algorithm', 'season']\n",
    "    )[['reward', 'distance', 'average_battery']]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "cumulative_station_df = (\n",
    "    df_station\n",
    "    .groupby(\n",
    "        ['episode', 'zone', 'aggregation', 'station_index', 'seed', 'exp_num', 'algorithm', 'season']\n",
    "    )[['traffic']]\n",
    "    .sum()\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Rename the 'reward' column to 'cumulative_reward' for clarity\n",
    "cumulative_agent_df.rename(columns={'reward': 'cumulative_reward'}, inplace=True)\n",
    "cumulative_agent_df.rename(columns={'average_battery': 'energy_used'}, inplace=True)\n",
    "\n",
    "# Get recalculated episodes using (aggregation number * episodes per aggregation) + episode number\n",
    "cumulative_agent_df['episode'] = cumulative_agent_df['aggregation'] * nn_c['num_episodes'] + cumulative_agent_df['episode']\n",
    "cumulative_station_df['episode'] = cumulative_station_df['aggregation'] * nn_c['num_episodes'] + cumulative_station_df['episode']\n",
    "\n",
    "\n",
    "cumulative_agent_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ff1db4-5dc3-4aca-ba32-aac8394eb865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming the cumulative_reward_df DataFrame is already available\n",
    "# If it's not, load your dataset into a DataFrame (e.g., pd.read_csv())\n",
    "\n",
    "# Define a function to calculate the required metrics\n",
    "def calculate_metrics(agent_data, station_data):\n",
    "    metrics = []\n",
    "    algorithms = agent_data['algorithm'].unique()\n",
    "    \n",
    "    for algo in algorithms:\n",
    "        algo_data = agent_data[agent_data['algorithm'] == algo]\n",
    "        algo_traffic_data = station_data[station_data['algorithm'] == algo]\n",
    "        \n",
    "        # Minimum metrics\n",
    "        min_reward = algo_data['cumulative_reward'].min()\n",
    "        min_distance = algo_data['distance'].min()\n",
    "        min_traffic = algo_traffic_data['traffic'].min()\n",
    "        min_energy = algo_data['energy_used'].min()\n",
    "        \n",
    "        # Average metrics\n",
    "        avg_reward = algo_data['cumulative_reward'].mean()\n",
    "        avg_distance = algo_data['distance'].mean()\n",
    "        avg_traffic = algo_traffic_data['traffic'].mean()\n",
    "        avg_energy = algo_data['energy_used'].mean()\n",
    "        \n",
    "        # Maximum metrics\n",
    "        max_reward = algo_data['cumulative_reward'].max()\n",
    "        max_distance = algo_data['distance'].max()\n",
    "        max_traffic = algo_traffic_data['traffic'].max()\n",
    "        max_energy = algo_data['energy_used'].max()\n",
    "        \n",
    "        metrics.append({\n",
    "            'Algorithm': algo,\n",
    "            'Min Reward': min_reward,\n",
    "            'Min Distance': min_distance,\n",
    "            'Min Traffic': min_traffic,\n",
    "            'Min Energy': min_energy,\n",
    "            'Avg Reward': avg_reward,\n",
    "            'Avg Distance': avg_distance,\n",
    "            'Avg Traffic': avg_traffic,\n",
    "            'Avg Energy': avg_energy,\n",
    "            'Max Reward': max_reward,\n",
    "            'Max Distance': max_distance,\n",
    "            'Max Traffic': max_traffic,\n",
    "            'Max Energy': max_energy\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(metrics)\n",
    "\n",
    "# Calculate the metrics\n",
    "metrics_df = calculate_metrics(cumulative_agent_df, cumulative_station_df) \n",
    "\n",
    "metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0607a2a7-5aae-4016-af67-095245cdc777",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_avg_reward_by_algorithm = cumulative_agent_df.groupby(['episode', 'algorithm', 'seed'])['cumulative_reward'].mean().reset_index()\n",
    "cumulative_avg_reward_by_algorithm['cumulative_reward'] = cumulative_avg_reward_by_algorithm.groupby(['algorithm', 'seed'])['cumulative_reward'].expanding().mean().reset_index(level=[0, 1], drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f6a19a-5c4d-49b4-8e48-a324614ae8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the cloud plot for each algorithm\n",
    "plt.figure(figsize=(8, 6))\n",
    "for algo in cumulative_avg_reward_by_algorithm['algorithm'].unique():\n",
    "    # Filter the data for the current zone\n",
    "    algo_data = cumulative_avg_reward_by_algorithm.loc[cumulative_avg_reward_by_algorithm['algorithm'] == algo]\n",
    "    min_cumulative_avg_reward = algo_data.groupby('episode')['cumulative_reward'].min()\n",
    "    max_cumulative_avg_reward = algo_data.groupby('episode')['cumulative_reward'].max()\n",
    "    mean_cumulative_avg_reward = algo_data.groupby('episode')['cumulative_reward'].mean()\n",
    "\n",
    "    plt.fill_between(\n",
    "        min_cumulative_avg_reward.index, \n",
    "        min_cumulative_avg_reward.values, \n",
    "        max_cumulative_avg_reward.values, \n",
    "        alpha=0.3\n",
    "    )\n",
    "    plt.plot(\n",
    "        mean_cumulative_avg_reward.index, \n",
    "        mean_cumulative_avg_reward.values, \n",
    "        label=f'Algorithm {algo} Average Reward'\n",
    "    )\n",
    "\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Cumulative Average Reward')\n",
    "plt.title(f'Aggs. {federated_c[\"aggregation_count\"]} - Eps. per agg. {nn_c[\"num_episodes\"]} - Cumulative Average Reward per Episode by Algorithm and Seed')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
