{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45773e86-ab4f-42f0-b5c2-eb9893e550ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "\n",
    "from evaluation import *\n",
    "from data_loader import *\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05f179a2-7dd0-4b64-a41b-36d53d61dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\n",
    "    \"DQN\": 'darkorange',\n",
    "    \"REINFORCE\": 'forestgreen',\n",
    "    \"CMA\": 'cyan',\n",
    "    \"ODT\": 'blueviolet',\n",
    "    'DENSER': 'gold'\n",
    "}\n",
    "\n",
    "season_colors = {\n",
    "    \"winter\": 'blue',\n",
    "    \"spring\": 'forestgreen',\n",
    "    \"summer\": 'gold',\n",
    "    \"autumn\": 'darkorange'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9203c8a6-d655-4e9f-b54b-8a046b10e77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for experiments 4162 to 4179\n"
     ]
    }
   ],
   "source": [
    "starting_exp = 4180\n",
    "ending_exp = 4188\n",
    "save_processed_data = True\n",
    "exp_lists_preformatted = [\n",
    "    '4000_4017.csv', '4018_4035.csv', '5000_5017.csv', '5018_5035.csv', '6000_6017.csv', '6018_6035.csv', # DQN\n",
    "    '4036_4053.csv', '4054_4071.csv', '5036_5053.csv', '5054_5071.csv', '6036_6053.csv', '6054_6071.csv', # REINFORCE\n",
    "    '4072_4089.csv', '4090_4107.csv', '5072_5089.csv', '5090_5107.csv', '6072_6089.csv', '6090_6107.csv', # CMA\n",
    "    '4108_4125.csv', '4126_4143.csv', '5108_5125.csv', '5126_5143.csv', '6108_6125.csv', '6126_6143.csv', # ODT 1\n",
    "    '4144_4161.csv', '4162_4179.csv', '5144_5161.csv', '5162_5179.csv', '6144_6161.csv', '6162_6179.csv' # ODT 2\n",
    "] # Existing formatted datasets\n",
    "#exp_lists_preformatted = ['4000_4000.csv', '4036_4036.csv']\n",
    "#exp_lists_preformatted = ['4000_4017.csv', '4018_4035.csv', '4036_4053.csv', '4054_4071.csv']\n",
    "#exp_lists_preformatted = []\n",
    "\n",
    "# TODO: REMOVE THIS!!\n",
    "index = 25\n",
    "starting_exp = int(exp_lists_preformatted[index].split(\"_\")[0])\n",
    "ending_exp = int(exp_lists_preformatted[index].split(\"_\")[1].split('.')[0])\n",
    "\n",
    "exp_lists_preformatted = []\n",
    "\n",
    "print(f\"Running for experiments {starting_exp} to {ending_exp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "047648a7-4749-4142-a7ee-134f4b48ec94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading None/train/metrics_agent_metrics.csv\n",
      "File None/train/metrics_agent_metrics.csv not found.\n",
      "Loading None/train/metrics_agent_metrics.csv\n",
      "File None/train/metrics_agent_metrics.csv not found.\n",
      "Loading None/train/metrics_agent_metrics.csv\n",
      "File None/train/metrics_agent_metrics.csv not found.\n",
      "Loading None/train/metrics_agent_metrics.csv\n",
      "File None/train/metrics_agent_metrics.csv not found.\n",
      "Loading None/train/metrics_agent_metrics.csv\n",
      "File None/train/metrics_agent_metrics.csv not found.\n",
      "Loading None/train/metrics_agent_metrics.csv\n",
      "File None/train/metrics_agent_metrics.csv not found.\n",
      "Loading None/train/metrics_agent_metrics.csv\n",
      "File None/train/metrics_agent_metrics.csv not found.\n",
      "Loading None/train/metrics_agent_metrics.csv\n",
      "File None/train/metrics_agent_metrics.csv not found.\n",
      "Loading None/train/metrics_agent_metrics.csv\n",
      "File None/train/metrics_agent_metrics.csv not found.\n",
      "Loading None/train/metrics_agent_metrics.csv\n",
      "File None/train/metrics_agent_metrics.csv not found.\n",
      "Loading None/train/metrics_agent_metrics.csv\n",
      "File None/train/metrics_agent_metrics.csv not found.\n",
      "Loading None/train/metrics_agent_metrics.csv\n",
      "File None/train/metrics_agent_metrics.csv not found.\n",
      "Loading None/train/metrics_agent_metrics.csv\n",
      "File None/train/metrics_agent_metrics.csv not found.\n",
      "Loading None/train/metrics_agent_metrics.csv\n",
      "File None/train/metrics_agent_metrics.csv not found.\n",
      "Loading None/train/metrics_agent_metrics.csv\n",
      "File None/train/metrics_agent_metrics.csv not found.\n",
      "Loading None/train/metrics_agent_metrics.csv\n",
      "File None/train/metrics_agent_metrics.csv not found.\n",
      "Loading None/train/metrics_agent_metrics.csv\n",
      "File None/train/metrics_agent_metrics.csv not found.\n",
      "Loading None/train/metrics_agent_metrics.csv\n",
      "File None/train/metrics_agent_metrics.csv not found.\n"
     ]
    }
   ],
   "source": [
    "experiments = range(starting_exp, ending_exp + 1)\n",
    "\n",
    "exp_agent_data = []\n",
    "\n",
    "agg_counts = []\n",
    "\n",
    "# REMOVE THIS\n",
    "#algos = ['DQN', 'PPO', 'CMA', 'ODT']\n",
    "\n",
    "if len(exp_lists_preformatted) == 0:\n",
    "    for ind, exp_num in enumerate(experiments):\n",
    "        config_fname = f'./Exp_{exp_num}/config.yaml'\n",
    "        \n",
    "        c = load_config_file(config_fname)\n",
    "        nn_c = c['nn_hyperparameters']\n",
    "        federated_c = c['federated_learning_settings']\n",
    "        algo_c = c['algorithm_settings']\n",
    "        env_c = c['environment_settings']\n",
    "        eval_c = c['eval_config']\n",
    "        cma_c = c['cma_parameters']\n",
    "    \n",
    "        ev_info = []\n",
    "    \n",
    "        seed = env_c['seed']\n",
    "    \n",
    "        algorithm_dm = algo_c['algorithm']\n",
    "        \n",
    "        def load_from_json_with_error_handling(filepath, columns_specific):\n",
    "            try:\n",
    "                return read_csv_data(filepath, columns=columns_specific)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON from {filepath}: {e.msg} at line {e.lineno}, column {e.colno}\")\n",
    "                return None  # Handle the error and return None or an empty object\n",
    "        \n",
    "        \n",
    "        path_list = [\n",
    "            f\"/storage_1/metrics/Exp_{exp_num}\", # for Huron\n",
    "            f\"/mnt/storage_1/merl/metrics/Exp_{exp_num}\", #for Aulavic\n",
    "            f\"../metrics/Exp_{exp_num}\", # neither on storage\n",
    "        ]\n",
    "\n",
    "        d_base = None\n",
    "        for path in path_list:\n",
    "            if os.path.exists(path):\n",
    "                d_base = path\n",
    "                break\n",
    "                \n",
    "        base_path = f\"{d_base}/train/metrics\"\n",
    "    \n",
    "        print(f'Loading {base_path}_agent_metrics.csv')\n",
    "        agent_data = load_from_json_with_error_handling(f'{base_path}_agent_metrics.csv', ['episode', 'timestep', 'done', 'zone', 'aggregation', 'agent_index', 'reward',])\n",
    "        \n",
    "        agent_data['seed'] = seed\n",
    "        agent_data['exp_num'] = exp_num\n",
    "        \n",
    "        agent_data['algorithm'] = algorithm_dm\n",
    "        # agent_data['algorithm'] = algos[ind % len(algos)] # REMOVE THIS AND UNCOMMENT PREVIOUS LINE!\n",
    "        \n",
    "        agent_data['season'] = env_c['season']\n",
    "        agent_data['num_aggs'] = federated_c['aggregation_count']\n",
    "        agent_data['eps_per_agg'] = cma_c['max_generations'] if algorithm_dm == 'CMA' else nn_c['num_episodes']\n",
    "    \n",
    "        exp_agent_data.append(agent_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c374987-9920-4ebe-903a-4383fff87814",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'episode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(exp_lists_preformatted) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;66;03m# Convert data to DataFrame for easier manipulation\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     df_agent \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(exp_agent_data, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m     cumulative_agent_df \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 6\u001b[0m         \u001b[43mdf_agent\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepisode\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mzone\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maggregation\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43magent_index\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mexp_num\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43malgorithm\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mseason\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnum_aggs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps_per_agg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;241m.\u001b[39msum()\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;241m.\u001b[39mreset_index()\n\u001b[1;32m     12\u001b[0m     )\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Rename the 'reward' column to 'cumulative_reward' for clarity\u001b[39;00m\n\u001b[1;32m     15\u001b[0m     cumulative_agent_df\u001b[38;5;241m.\u001b[39mrename(columns\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcumulative_reward\u001b[39m\u001b[38;5;124m'\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py:8252\u001b[0m, in \u001b[0;36mDataFrame.groupby\u001b[0;34m(self, by, axis, level, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m   8249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to supply one of \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mby\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlevel\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   8250\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n\u001b[0;32m-> 8252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameGroupBy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   8253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8255\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mas_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mas_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8258\u001b[0m \u001b[43m    \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8259\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8260\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   8262\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/groupby/groupby.py:931\u001b[0m, in \u001b[0;36mGroupBy.__init__\u001b[0;34m(self, obj, keys, axis, level, grouper, exclusions, selection, as_index, sort, group_keys, observed, dropna)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropna \u001b[38;5;241m=\u001b[39m dropna\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grouper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     grouper, exclusions, obj \u001b[38;5;241m=\u001b[39m \u001b[43mget_grouper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    932\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    934\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    935\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    936\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobserved\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobserved\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdropna\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdropna\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj \u001b[38;5;241m=\u001b[39m obj\n\u001b[1;32m    942\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxis \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_get_axis_number(axis)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/groupby/grouper.py:985\u001b[0m, in \u001b[0;36mget_grouper\u001b[0;34m(obj, key, axis, level, sort, observed, validate, dropna)\u001b[0m\n\u001b[1;32m    983\u001b[0m         in_axis, level, gpr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m, gpr, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    984\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 985\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(gpr)\n\u001b[1;32m    986\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(gpr, Grouper) \u001b[38;5;129;01mand\u001b[39;00m gpr\u001b[38;5;241m.\u001b[39mkey \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;66;03m# Add key to exclusions\u001b[39;00m\n\u001b[1;32m    988\u001b[0m     exclusions\u001b[38;5;241m.\u001b[39madd(gpr\u001b[38;5;241m.\u001b[39mkey)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'episode'"
     ]
    }
   ],
   "source": [
    "if len(exp_lists_preformatted) == 0:\n",
    "    # Convert data to DataFrame for easier manipulation\n",
    "    df_agent = pd.concat(exp_agent_data, ignore_index=True)\n",
    "    \n",
    "    cumulative_agent_df = (\n",
    "        df_agent\n",
    "        .groupby(\n",
    "            ['episode', 'zone', 'aggregation', 'agent_index', 'seed', 'exp_num', 'algorithm', 'season', 'num_aggs', 'eps_per_agg']\n",
    "        )['reward']\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    # Rename the 'reward' column to 'cumulative_reward' for clarity\n",
    "    cumulative_agent_df.rename(columns={'reward': 'cumulative_reward'}, inplace=True)\n",
    "    \n",
    "    # Get recalculated episodes using (aggregation number * episodes per aggregation) + episode number\n",
    "    cumulative_agent_df['episode'] = cumulative_agent_df['aggregation'] * cumulative_agent_df['eps_per_agg'] + cumulative_agent_df['episode']\n",
    "    \n",
    "    cumulative_agent_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0607a2a7-5aae-4016-af67-095245cdc777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path with starting_exp and ending_exp variables\n",
    "file_path_for_processed_data = f'../../../../storage_1/metrics/formatted_experiment_data/part_1/'\n",
    "\n",
    "if len(exp_lists_preformatted) == 0:\n",
    "    cumulative_avg_reward_by_algorithm = (\n",
    "        cumulative_agent_df\n",
    "        .groupby(['episode', 'algorithm', 'seed', 'num_aggs', 'season'])['cumulative_reward']\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    cumulative_avg_reward_by_algorithm = cumulative_avg_reward_by_algorithm.sort_values(\n",
    "        ['season', 'algorithm', 'seed', 'num_aggs', 'episode']\n",
    "    )\n",
    "    \n",
    "    cumulative_avg_reward_by_algorithm['cumulative_reward'] = (\n",
    "        cumulative_avg_reward_by_algorithm\n",
    "        .groupby(['algorithm', 'seed', 'num_aggs', 'season'])['cumulative_reward']\n",
    "        .transform(lambda x: x.expanding().mean())\n",
    "    )\n",
    "\n",
    "    if save_processed_data:\n",
    "        if not os.path.exists(file_path_for_processed_data):\n",
    "            os.makedirs(file_path_for_processed_data)\n",
    "        \n",
    "        # Save the DataFrame to a CSV file\n",
    "        cumulative_avg_reward_by_algorithm.to_csv(f\"{file_path_for_processed_data}/{starting_exp}_{ending_exp}.csv\", index=False)\n",
    "        \n",
    "        print(f\"Data successfully saved to {file_path_for_processed_data}/{starting_exp}_{ending_exp}.csv\")\n",
    "\n",
    "if len(exp_lists_preformatted) > 0:\n",
    "    dataframes = []\n",
    "    \n",
    "    # Load and combine datasets\n",
    "    for existing_set in exp_lists_preformatted:\n",
    "        loaded_dataset = pd.read_csv(f\"{file_path_for_processed_data}/{existing_set}\")\n",
    "        # Combine datasets\n",
    "        dataframes.append(loaded_dataset)\n",
    "\n",
    "    cumulative_avg_reward_by_algorithm = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6da4ddf-48e3-4b9c-bd6c-a28a4e4fd9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_avg_reward_by_algorithm['num_aggs'] = np.where(\n",
    "    (cumulative_avg_reward_by_algorithm['num_aggs'] == 3) & \n",
    "    (cumulative_avg_reward_by_algorithm['algorithm'].isin(['CMA', 'DENSER'])), \n",
    "    1, \n",
    "    cumulative_avg_reward_by_algorithm['num_aggs']\n",
    ")\n",
    "\n",
    "# Initialize lists to store legend handles and labels\n",
    "algorithm_handles = []\n",
    "algorithm_labels = []\n",
    "algorithms_added = set()\n",
    "\n",
    "season_handles = []\n",
    "season_labels = []\n",
    "seasons_added = set()\n",
    "\n",
    "# Begin plotting\n",
    "agg_levels_sorted = sorted(cumulative_avg_reward_by_algorithm['num_aggs'].unique(), reverse=False)\n",
    "num_plots = len(agg_levels_sorted)\n",
    "fig, axes = plt.subplots(1, num_plots, figsize=(16, 5), sharey=True, sharex=True)\n",
    "\n",
    "# Set global font size\n",
    "plt.rcParams.update({\n",
    "    'font.size': 14,             # Base font size\n",
    "    'axes.titlesize': 16,        # Font size for axes titles\n",
    "    'axes.labelsize': 16,        # Font size for x and y labels\n",
    "    'xtick.labelsize': 14,       # Font size for x-axis ticks\n",
    "    'ytick.labelsize': 16,       # Font size for y-axis ticks\n",
    "    'legend.fontsize': 16,       # Font size for legend text\n",
    "    'figure.titlesize': 18       # Font size for figure titles\n",
    "})\n",
    "\n",
    "axes = np.atleast_1d(axes)\n",
    "\n",
    "for plot_ind, agg_level in enumerate(agg_levels_sorted):\n",
    "    ax = axes[plot_ind]\n",
    "    \n",
    "    agg_level_data = cumulative_avg_reward_by_algorithm.loc[\n",
    "        cumulative_avg_reward_by_algorithm['num_aggs'] == agg_level\n",
    "    ]\n",
    "\n",
    "    total_eps = agg_level_data['episode'].max()\n",
    "    eps_per_agg = np.ceil(total_eps / agg_level)\n",
    "        \n",
    "    for algo in agg_level_data['algorithm'].unique():\n",
    "        # Filter the data for the current algorithm\n",
    "        algo_data = agg_level_data[agg_level_data['algorithm'] == algo]\n",
    "        \n",
    "        min_cumulative_avg_reward = algo_data.groupby('episode')['cumulative_reward'].min()\n",
    "        max_cumulative_avg_reward = algo_data.groupby('episode')['cumulative_reward'].max()\n",
    "        mean_cumulative_avg_reward = algo_data.groupby('episode')['cumulative_reward'].mean()\n",
    "    \n",
    "        ax.fill_between(\n",
    "            min_cumulative_avg_reward.index, \n",
    "            min_cumulative_avg_reward.values, \n",
    "            max_cumulative_avg_reward.values,\n",
    "            color=colors[algo],\n",
    "            alpha=0.3\n",
    "        )\n",
    "        # Plot the mean cumulative average reward\n",
    "        line, = ax.plot(\n",
    "            mean_cumulative_avg_reward.index, \n",
    "            mean_cumulative_avg_reward.values,\n",
    "            color=colors[algo]\n",
    "        )\n",
    "        \n",
    "        # Collect algorithm handles and labels if not already added\n",
    "        if algo not in algorithms_added:\n",
    "            algorithm_handles.append(line)\n",
    "            algorithm_labels.append(f'{algo} Average Reward')\n",
    "            algorithms_added.add(algo)\n",
    "\n",
    "    # Plot aggregation lines\n",
    "    for agg in range(1, agg_level + 1):\n",
    "        if agg == 1:\n",
    "            ax.axvline(x=(agg * eps_per_agg), color='r', linestyle='--', linewidth=1, alpha=0.7)\n",
    "        else:\n",
    "            ax.axvline(x=(agg * eps_per_agg), color='r', linestyle='--', linewidth=1, alpha=0.7)\n",
    "\n",
    "    ax.set_xlabel('Episode')\n",
    "    ax.grid(True)\n",
    "    ax.set_xlim(0, 10000)\n",
    "\n",
    "# Set the shared y-label\n",
    "axes[0].set_ylabel('Cumulative Average Reward')\n",
    "\n",
    "# Create a custom legend entry for aggregation lines\n",
    "aggregation_handle = Line2D(\n",
    "    [0], [0], color='r', linestyle='--', linewidth=1, alpha=0.7, label='Aggregation'\n",
    ")\n",
    "\n",
    "# Combine all legend handles and labels\n",
    "handles = algorithm_handles + [aggregation_handle]\n",
    "\n",
    "#labels = algorithm_labels + ['Aggregation', 'Winter', 'Summer']\n",
    "labels = algorithm_labels + ['Aggregation']\n",
    "\n",
    "# Place the legend outside of the subplots\n",
    "fig.legend(handles, labels, loc='lower center', ncol=len(handles), bbox_to_anchor=(0.5, 0.13))\n",
    "\n",
    "# Adjust layout to make room for the legend\n",
    "fig.tight_layout(rect=[0, 0, 1, 1])\n",
    "\n",
    "fig.savefig('./Figures/aggregation_comparison.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcc2014-aa78-4b4d-a32f-cd8da8174ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_avg_reward_by_algorithm['num_aggs'] = np.where(\n",
    "    (cumulative_avg_reward_by_algorithm['num_aggs'] == 3) & \n",
    "    (cumulative_avg_reward_by_algorithm['algorithm'].isin(['CMA', 'DENSER'])), \n",
    "    1, \n",
    "    cumulative_avg_reward_by_algorithm['num_aggs']\n",
    ")\n",
    "\n",
    "# Initialize lists to store legend handles and labels\n",
    "algorithm_handles = []\n",
    "algorithm_labels = []\n",
    "algorithms_added = set()\n",
    "\n",
    "season_handles = []\n",
    "season_labels = []\n",
    "seasons_added = set()\n",
    "\n",
    "# Begin plotting\n",
    "agg_levels_sorted = sorted(cumulative_avg_reward_by_algorithm['num_aggs'].unique(), reverse=False)\n",
    "num_plots = len(agg_levels_sorted)\n",
    "fig, axes = plt.subplots(1, num_plots, figsize=(16, 5), sharey=True, sharex=True)\n",
    "\n",
    "# Set global font size\n",
    "plt.rcParams.update({\n",
    "    'font.size': 14,             # Base font size\n",
    "    'axes.titlesize': 16,        # Font size for axes titles\n",
    "    'axes.labelsize': 16,        # Font size for x and y labels\n",
    "    'xtick.labelsize': 14,       # Font size for x-axis ticks\n",
    "    'ytick.labelsize': 16,       # Font size for y-axis ticks\n",
    "    'legend.fontsize': 16,       # Font size for legend text\n",
    "    'figure.titlesize': 18       # Font size for figure titles\n",
    "})\n",
    "\n",
    "axes = np.atleast_1d(axes)\n",
    "\n",
    "for plot_ind, agg_level in enumerate(agg_levels_sorted):\n",
    "    ax = axes[plot_ind]\n",
    "    \n",
    "    agg_level_data = cumulative_avg_reward_by_algorithm.loc[\n",
    "        cumulative_avg_reward_by_algorithm['num_aggs'] == agg_level\n",
    "    ]\n",
    "\n",
    "    total_eps = agg_level_data['episode'].max()\n",
    "    eps_per_agg = np.ceil(total_eps / agg_level)\n",
    "\n",
    "    for season in agg_level_data['season'].unique():\n",
    "        season_data = agg_level_data[agg_level_data['season'] == season]\n",
    "        \n",
    "        for algo in season_data['algorithm'].unique():\n",
    "            # Filter the data for the current algorithm\n",
    "            algo_data = season_data[season_data['algorithm'] == algo]\n",
    "            \n",
    "            min_cumulative_avg_reward = algo_data.groupby('episode')['cumulative_reward'].min()\n",
    "            max_cumulative_avg_reward = algo_data.groupby('episode')['cumulative_reward'].max()\n",
    "            mean_cumulative_avg_reward = algo_data.groupby('episode')['cumulative_reward'].mean()\n",
    "        \n",
    "            ax.fill_between(\n",
    "                min_cumulative_avg_reward.index, \n",
    "                min_cumulative_avg_reward.values, \n",
    "                max_cumulative_avg_reward.values,\n",
    "                color=season_colors[season],\n",
    "                #color=color[algo]\n",
    "                alpha=0.3\n",
    "            )\n",
    "            # Plot the mean cumulative average reward\n",
    "            line, = ax.plot(\n",
    "                mean_cumulative_avg_reward.index, \n",
    "                mean_cumulative_avg_reward.values,\n",
    "                color=season_colors[season]\n",
    "                #color=color[algo]\n",
    "            )\n",
    "            \n",
    "            # Collect algorithm handles and labels if not already added\n",
    "            if algo not in algorithms_added:\n",
    "                algorithm_handles.append(line)\n",
    "                algorithm_labels.append(f'{algo} Average Reward')\n",
    "                algorithms_added.add(algo)\n",
    "\n",
    "        if season not in seasons_added:\n",
    "            season_handles.append(line)\n",
    "            season_labels.append(f'{season}')\n",
    "            seasons_added.add(season)\n",
    "\n",
    "    # Plot aggregation lines\n",
    "    for agg in range(1, agg_level + 1):\n",
    "        if agg == 1:\n",
    "            ax.axvline(x=(agg * eps_per_agg), color='r', linestyle='--', linewidth=1, alpha=0.7)\n",
    "        else:\n",
    "            ax.axvline(x=(agg * eps_per_agg), color='r', linestyle='--', linewidth=1, alpha=0.7)\n",
    "\n",
    "    # # Shade the seasons across the entire x-axis range\n",
    "    # x_min, x_max = ax.get_xlim()\n",
    "    # x_values = np.linspace(x_min, x_max, num=1000)\n",
    "    # y_min, y_max = ax.get_ylim()\n",
    "    # y_mid = (y_max + y_min) / 2  # Midpoint of y-axis for shading\n",
    "\n",
    "    # # Create shading for seasons\n",
    "    # winter_shade = ax.fill_between(\n",
    "    #     x=x_values, \n",
    "    #     y1=y_min, \n",
    "    #     y2=y_mid, \n",
    "    #     color='lightblue', \n",
    "    #     alpha=0.2\n",
    "    # )\n",
    "    # summer_shade = ax.fill_between(\n",
    "    #     x=x_values, \n",
    "    #     y1=y_mid, \n",
    "    #     y2=y_max, \n",
    "    #     color='orange', \n",
    "    #     alpha=0.1\n",
    "    # )\n",
    "\n",
    "    # Remove legends from individual subplots\n",
    "    # We don't call ax.legend() here to prevent individual legends\n",
    "\n",
    "    ax.set_xlabel('Episode')\n",
    "    ax.grid(True)\n",
    "    ax.set_xlim(0, 10000)\n",
    "\n",
    "# Set the shared y-label\n",
    "axes[0].set_ylabel('Cumulative Average Reward')\n",
    "\n",
    "# Create custom legend entries for seasons\n",
    "# winter_handle = Patch(facecolor='lightblue', edgecolor='lightblue', alpha=0.2, label='Winter')\n",
    "# summer_handle = Patch(facecolor='orange', edgecolor='orange', alpha=0.1, label='Summer')\n",
    "\n",
    "# Create a custom legend entry for aggregation lines\n",
    "aggregation_handle = Line2D(\n",
    "    [0], [0], color='r', linestyle='--', linewidth=1, alpha=0.7, label='Aggregation'\n",
    ")\n",
    "\n",
    "# Combine all legend handles and labels\n",
    "#handles = algorithm_handles + [aggregation_handle, winter_handle, summer_handle]\n",
    "handles = algorithm_handles + [aggregation_handle] + season_handles\n",
    "\n",
    "#labels = algorithm_labels + ['Aggregation', 'Winter', 'Summer']\n",
    "labels = algorithm_labels + ['Aggregation'] + season_labels\n",
    "\n",
    "# Place the legend outside of the subplots\n",
    "fig.legend(handles, labels, loc='lower center', ncol=len(handles), bbox_to_anchor=(0.5, 0.13))\n",
    "\n",
    "# Adjust layout to make room for the legend\n",
    "fig.tight_layout(rect=[0, 0, 1, 1])\n",
    "\n",
    "fig.savefig('./Figures/aggregation_comparison.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4089aee-db7f-45f3-803d-12481e0107c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create average\n",
    "grouped = cumulative_avg_reward_by_algorithm.groupby(['algorithm', 'season', 'episode'])['cumulative_reward'].mean().reset_index()\n",
    "summary = grouped.groupby(['algorithm', 'season'])['cumulative_reward'].agg(['mean', 'std']).reset_index()\n",
    "summary.rename(columns={'algorithm': 'model', 'mean': 'avg_reward', 'std': 'std_reward'}, inplace=True)\n",
    "\n",
    "# Save average data\n",
    "path_names = [name.replace('.csv', '_') for name in exp_lists_preformatted]\n",
    "path = ''.join(path_names)\n",
    "path = 'Exps_' + path + 'averages.csv'\n",
    "print(f\"Saved to {path}\")\n",
    "\n",
    "summary.to_csv(path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e3b8e2-7b63-4da4-85ab-29b904ec7b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_avg_reward_by_algorithm['num_aggs'] = np.where(\n",
    "    (cumulative_avg_reward_by_algorithm['num_aggs'] == 3) & \n",
    "    (cumulative_avg_reward_by_algorithm['algorithm'].isin(['CMA', 'DENSER'])), \n",
    "    1, \n",
    "    cumulative_avg_reward_by_algorithm['num_aggs']\n",
    ")mkdir \n",
    "\n",
    "agg_levels_sorted = sorted(cumulative_avg_reward_by_algorithm['num_aggs'].unique(), reverse=False)\n",
    "\n",
    "num_plots = len(cumulative_avg_reward_by_algorithm['num_aggs'].unique())\n",
    "\n",
    "fig, axes = plt.subplots(num_plots, 1, figsize=(6, 8), sharey=True, sharex=True)  # Adjust figsize as needed\n",
    "\n",
    "for plot_ind, agg_level in enumerate(agg_levels_sorted):\n",
    "    ax = axes[plot_ind]\n",
    "    \n",
    "    agg_level_data = cumulative_avg_reward_by_algorithm.loc[cumulative_avg_reward_by_algorithm['num_aggs'] == agg_level]\n",
    "\n",
    "    total_eps = agg_level_data['episode'].max()\n",
    "    eps_per_agg = np.ceil(total_eps / agg_level)\n",
    "\n",
    "    for season in agg_level_data['season'].unique():\n",
    "        season_data = agg_level_data[agg_level_data['season'] == season]\n",
    "        \n",
    "        for algo in season_data['algorithm'].unique():\n",
    "            # Filter the data for the current zone\n",
    "            algo_data = season_data[season_data['algorithm'] == algo]\n",
    "            \n",
    "            min_cumulative_avg_reward = algo_data.groupby('episode')['cumulative_reward'].min()\n",
    "            max_cumulative_avg_reward = algo_data.groupby('episode')['cumulative_reward'].max()\n",
    "            mean_cumulative_avg_reward = algo_data.groupby('episode')['cumulative_reward'].mean()\n",
    "        \n",
    "            ax.fill_between(\n",
    "                min_cumulative_avg_reward.index, \n",
    "                min_cumulative_avg_reward.values, \n",
    "                max_cumulative_avg_reward.values,\n",
    "                color=colors[algo],\n",
    "                alpha=0.3\n",
    "            )\n",
    "            if season == 'summer':\n",
    "                ax.plot(\n",
    "                    mean_cumulative_avg_reward.index, \n",
    "                    mean_cumulative_avg_reward.values,\n",
    "                    color=colors[algo],\n",
    "                    label=f'{algo} Average Reward'\n",
    "                )\n",
    "            else:\n",
    "                ax.plot(\n",
    "                    mean_cumulative_avg_reward.index, \n",
    "                    mean_cumulative_avg_reward.values,\n",
    "                    color=colors[algo]\n",
    "                )\n",
    "\n",
    "    for agg in range(1, agg_level + 1):\n",
    "        if agg == 1:\n",
    "            ax.axvline(x=(agg * eps_per_agg), color='r', linestyle='--', linewidth=1, label='Aggregation', alpha=0.7)\n",
    "        else:\n",
    "            ax.axvline(x=(agg * eps_per_agg), color='r', linestyle='--', linewidth=1, alpha=0.7)\n",
    "    \n",
    "    axes[-1].set_xlabel('Episode')\n",
    "    ax.set_ylabel('Cumulative Average Reward')\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.grid(True)\n",
    "    ax.set_xlim(0, 5000)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
