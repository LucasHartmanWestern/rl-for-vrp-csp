{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45773e86-ab4f-42f0-b5c2-eb9893e550ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "\n",
    "from evaluation import *\n",
    "from data_loader import *\n",
    "import random\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05f179a2-7dd0-4b64-a41b-36d53d61dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\n",
    "    \"DQN\": 'darkorange',\n",
    "    \"PPO\": 'forestgreen',\n",
    "    \"CMA\": 'cyan',\n",
    "    \"ODT\": 'blueviolet'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047648a7-4749-4142-a7ee-134f4b48ec94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../../../../storage_1/metrics/Exp_4000/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4001/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4002/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4003/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4004/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4005/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4006/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4007/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4008/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4009/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4010/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4011/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4012/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4013/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4014/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4015/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4016/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4017/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4018/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4019/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4020/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4021/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4022/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4023/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4024/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4025/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4026/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4027/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4028/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4029/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4030/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4031/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4032/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4033/train/metrics_agent_metrics.csv\n",
      "Loading ../../../../storage_1/metrics/Exp_4034/train/metrics_agent_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "starting_exp = 4000\n",
    "ending_exp = 4035\n",
    "save_processed_data = True\n",
    "#exp_lists_preformatted = ['4000_4035.csv', '4072_4107.csv'] # Existing formatted datasets\n",
    "exp_lists_preformatted = []\n",
    "\n",
    "\n",
    "experiments = range(starting_exp, ending_exp + 1)\n",
    "\n",
    "exp_agent_data = []\n",
    "\n",
    "agg_counts = []\n",
    "\n",
    "# REMOVE THIS\n",
    "#algos = ['DQN', 'PPO', 'CMA', 'ODT']\n",
    "\n",
    "if len(exp_lists_preformatted) == 0:\n",
    "    for ind, exp_num in enumerate(experiments):\n",
    "        config_fname = f'./Exp_{exp_num}/config.yaml'\n",
    "        \n",
    "        c = load_config_file(config_fname)\n",
    "        nn_c = c['nn_hyperparameters']\n",
    "        federated_c = c['federated_learning_settings']\n",
    "        algo_c = c['algorithm_settings']\n",
    "        env_c = c['environment_settings']\n",
    "        eval_c = c['eval_config']\n",
    "    \n",
    "        ev_info = []\n",
    "    \n",
    "        seed = env_c['seed']\n",
    "    \n",
    "        algorithm_dm = algo_c['algorithm']\n",
    "        \n",
    "        def load_from_json_with_error_handling(filepath, columns_specific):\n",
    "            try:\n",
    "                return read_csv_data(filepath, columns=columns_specific)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON from {filepath}: {e.msg} at line {e.lineno}, column {e.colno}\")\n",
    "                return None  # Handle the error and return None or an empty object\n",
    "        \n",
    "        \n",
    "        d_base = f\"../../../../storage_1/metrics/Exp_{exp_num}\"\n",
    "        \n",
    "        if not os.path.exists(d_base):\n",
    "            d_base = f\"../metrics/Exp_{exp_num}\"\n",
    "                \n",
    "        base_path = f\"{d_base}/train/metrics\"\n",
    "    \n",
    "        print(f'Loading {base_path}_agent_metrics.csv')\n",
    "        agent_data = load_from_json_with_error_handling(f'{base_path}_agent_metrics.csv', ['episode', 'timestep', 'done', 'zone', 'aggregation', 'agent_index', 'reward',])\n",
    "        \n",
    "        agent_data['seed'] = seed\n",
    "        agent_data['exp_num'] = exp_num\n",
    "        \n",
    "        agent_data['algorithm'] = algorithm_dm\n",
    "        # agent_data['algorithm'] = algos[ind % len(algos)] # REMOVE THIS AND UNCOMMENT PREVIOUS LINE!\n",
    "        \n",
    "        agent_data['season'] = env_c['season']\n",
    "        agent_data['num_aggs'] = federated_c['aggregation_count']\n",
    "        agent_data['eps_per_agg'] = nn_c['num_episodes']\n",
    "    \n",
    "        exp_agent_data.append(agent_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c374987-9920-4ebe-903a-4383fff87814",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(exp_lists_preformatted) == 0:\n",
    "    # Convert data to DataFrame for easier manipulation\n",
    "    df_agent = pd.concat(exp_agent_data, ignore_index=True)\n",
    "    \n",
    "    cumulative_agent_df = (\n",
    "        df_agent\n",
    "        .groupby(\n",
    "            ['episode', 'zone', 'aggregation', 'agent_index', 'seed', 'exp_num', 'algorithm', 'season', 'num_aggs', 'eps_per_agg']\n",
    "        )['reward']\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    # Rename the 'reward' column to 'cumulative_reward' for clarity\n",
    "    cumulative_agent_df.rename(columns={'reward': 'cumulative_reward'}, inplace=True)\n",
    "    \n",
    "    # Get recalculated episodes using (aggregation number * episodes per aggregation) + episode number\n",
    "    cumulative_agent_df['episode'] = cumulative_agent_df['aggregation'] * cumulative_agent_df['eps_per_agg'] + cumulative_agent_df['episode']\n",
    "    \n",
    "    cumulative_agent_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0607a2a7-5aae-4016-af67-095245cdc777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file path with starting_exp and ending_exp variables\n",
    "file_path_for_processed_data = f'../../../../storage_1/metrics/formatted_experiment_data/part_1/'\n",
    "\n",
    "if len(exp_lists_preformatted) == 0:\n",
    "    cumulative_avg_reward_by_algorithm = (\n",
    "        cumulative_agent_df\n",
    "        .groupby(['episode', 'algorithm', 'seed', 'num_aggs', 'season'])['cumulative_reward']\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    cumulative_avg_reward_by_algorithm = cumulative_avg_reward_by_algorithm.sort_values(\n",
    "        ['season', 'algorithm', 'seed', 'num_aggs', 'episode']\n",
    "    )\n",
    "    \n",
    "    cumulative_avg_reward_by_algorithm['cumulative_reward'] = (\n",
    "        cumulative_avg_reward_by_algorithm\n",
    "        .groupby(['algorithm', 'seed', 'num_aggs', 'season'])['cumulative_reward']\n",
    "        .transform(lambda x: x.expanding().mean())\n",
    "    )\n",
    "\n",
    "    if save_processed_data:\n",
    "        if not os.path.exists(file_path_for_processed_data):\n",
    "            os.makedirs(file_path_for_processed_data)\n",
    "        \n",
    "        # Save the DataFrame to a CSV file\n",
    "        cumulative_avg_reward_by_algorithm.to_csv(f\"{file_path_for_processed_data}/{starting_exp}_{ending_exp}.csv\", index=False)\n",
    "        \n",
    "        print(f\"Data successfully saved to {file_path_for_processed_data}/{starting_exp}_{ending_exp}.csv\")\n",
    "\n",
    "if len(exp_lists_preformatted) > 0:\n",
    "    dataframes = []\n",
    "    \n",
    "    # Load and combine datasets\n",
    "    for existing_set in exp_lists_preformatted:\n",
    "        loaded_dataset = pd.read_csv(f\"{file_path_for_processed_data}/{existing_set}\")\n",
    "        # Combine datasets\n",
    "        dataframes.append(loaded_dataset)\n",
    "\n",
    "    cumulative_avg_reward_by_algorithm = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f6a19a-5c4d-49b4-8e48-a324614ae8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_avg_reward_by_algorithm['num_aggs'] = np.where(\n",
    "    (cumulative_avg_reward_by_algorithm['num_aggs'] == 3) & \n",
    "    (cumulative_avg_reward_by_algorithm['algorithm'] == 'CMA'), \n",
    "    1, \n",
    "    cumulative_avg_reward_by_algorithm['num_aggs']\n",
    ")\n",
    "\n",
    "agg_levels_sorted = sorted(cumulative_avg_reward_by_algorithm['num_aggs'].unique(), reverse=False)\n",
    "\n",
    "num_plots = len(cumulative_avg_reward_by_algorithm['num_aggs'].unique())\n",
    "\n",
    "fig, axes = plt.subplots(1, num_plots, figsize=(24, 6), sharey=True)  # Adjust figsize as needed\n",
    "\n",
    "for plot_ind, agg_level in enumerate(agg_levels_sorted):\n",
    "    ax = axes[plot_ind]\n",
    "    \n",
    "    agg_level_data = cumulative_avg_reward_by_algorithm.loc[cumulative_avg_reward_by_algorithm['num_aggs'] == agg_level]\n",
    "\n",
    "    total_eps = agg_level_data['episode'].max()\n",
    "    eps_per_agg = np.ceil(total_eps / agg_level)\n",
    "\n",
    "    for season in agg_level_data['season'].unique():\n",
    "        season_data = agg_level_data[agg_level_data['season'] == season]\n",
    "        \n",
    "        for algo in season_data['algorithm'].unique():\n",
    "            # Filter the data for the current zone\n",
    "            algo_data = season_data[season_data['algorithm'] == algo]\n",
    "            \n",
    "            min_cumulative_avg_reward = algo_data.groupby('episode')['cumulative_reward'].min()\n",
    "            max_cumulative_avg_reward = algo_data.groupby('episode')['cumulative_reward'].max()\n",
    "            mean_cumulative_avg_reward = algo_data.groupby('episode')['cumulative_reward'].mean()\n",
    "        \n",
    "            ax.fill_between(\n",
    "                min_cumulative_avg_reward.index, \n",
    "                min_cumulative_avg_reward.values, \n",
    "                max_cumulative_avg_reward.values,\n",
    "                color=colors[algo],\n",
    "                alpha=0.3\n",
    "            )\n",
    "            ax.plot(\n",
    "                mean_cumulative_avg_reward.index, \n",
    "                mean_cumulative_avg_reward.values,\n",
    "                color=colors[algo],\n",
    "                label=f'Algorithm {algo} Average Reward - Season {season}'\n",
    "            )\n",
    "\n",
    "    for agg in range(1, agg_level + 1):\n",
    "        if agg == 1:\n",
    "            ax.axvline(x=(agg * eps_per_agg), color='r', linestyle='--', linewidth=1, label='Aggregation', alpha=0.3)\n",
    "        else:\n",
    "            ax.axvline(x=(agg * eps_per_agg), color='r', linestyle='--', linewidth=1, alpha=0.3)\n",
    "    \n",
    "    ax.set_xlabel('Episode')\n",
    "    axes[0].set_ylabel('Cumulative Average Reward')\n",
    "    ax.set_title(f'{agg_level} Aggregations')\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.grid(True)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e3b8e2-7b63-4da4-85ab-29b904ec7b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_levels_sorted = sorted(cumulative_avg_reward_by_algorithm['num_aggs'].unique(), reverse=True)\n",
    "\n",
    "num_plots = len(cumulative_avg_reward_by_algorithm['num_aggs'].unique())\n",
    "\n",
    "fig, axes = plt.subplots(num_plots, 1, figsize=(8, 16))  # Adjust figsize as needed\n",
    "\n",
    "for plot_ind, agg_level in enumerate(agg_levels_sorted):\n",
    "    ax = axes[plot_ind]\n",
    "    \n",
    "    agg_level_data = cumulative_avg_reward_by_algorithm.loc[cumulative_avg_reward_by_algorithm['num_aggs'] == agg_level]\n",
    "\n",
    "    total_eps = agg_level_data['episode'].max()\n",
    "    eps_per_agg = np.ceil(total_eps / agg_level)\n",
    "\n",
    "    for season in agg_level_data['season'].unique():\n",
    "        season_data = agg_level_data[agg_level_data['season'] == season]\n",
    "        \n",
    "        for algo in season_data['algorithm'].unique():\n",
    "            # Filter the data for the current zone\n",
    "            algo_data = season_data[season_data['algorithm'] == algo]\n",
    "            \n",
    "            min_cumulative_avg_reward = algo_data.groupby('episode')['cumulative_reward'].min()\n",
    "            max_cumulative_avg_reward = algo_data.groupby('episode')['cumulative_reward'].max()\n",
    "            mean_cumulative_avg_reward = algo_data.groupby('episode')['cumulative_reward'].mean()\n",
    "        \n",
    "            ax.fill_between(\n",
    "                min_cumulative_avg_reward.index, \n",
    "                min_cumulative_avg_reward.values, \n",
    "                max_cumulative_avg_reward.values, \n",
    "                alpha=0.3\n",
    "            )\n",
    "            ax.plot(\n",
    "                mean_cumulative_avg_reward.index, \n",
    "                mean_cumulative_avg_reward.values, \n",
    "                label=f'Algorithm {algo} Average Reward - Season {season}'\n",
    "            )\n",
    "\n",
    "    for agg in range(1, agg_level + 1):\n",
    "        if agg == 1:\n",
    "            ax.axvline(x=(agg * eps_per_agg), color='r', linestyle='--', linewidth=1, label='Aggregation')\n",
    "        else:\n",
    "            ax.axvline(x=(agg * eps_per_agg), color='r', linestyle='--', linewidth=1)\n",
    "        \n",
    "    ax.set_xlabel('Episode')\n",
    "    ax.set_ylabel('Cumulative Average Reward')\n",
    "    ax.set_title(f'{agg_level} Aggregations')\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.grid(True)\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
