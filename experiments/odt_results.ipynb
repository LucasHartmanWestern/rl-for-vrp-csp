{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e41dd8b7-fe9f-4943-aa1f-46dfa901fd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "from matplotlib.lines import Line2D\n",
    "import yaml  # If not installed: pip install pyyaml\n",
    "\n",
    "# Set up algorithm colors\n",
    "colors = {\n",
    "    \"DQN\": 'darkorange',\n",
    "    \"PPO\": 'forestgreen',\n",
    "    \"CMA\": 'cyan',\n",
    "    \"ODT\": 'blueviolet'\n",
    "}\n",
    "\n",
    "# Helper functions\n",
    "def load_config_file(filepath):\n",
    "    with open(filepath, 'r') as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "def read_csv_data(filepath, columns):\n",
    "    return pd.read_csv(filepath, usecols=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd181982-1649-486f-859a-ee439d7d645a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /storage_1/metrics/Exp_6108/train/metrics_agent_metrics.csv for experiment 6108\n",
      "Loading /storage_1/metrics/Exp_6109/train/metrics_agent_metrics.csv for experiment 6109\n",
      "Loading /storage_1/metrics/Exp_6110/train/metrics_agent_metrics.csv for experiment 6110\n",
      "Data successfully saved to ./processed_data/6108_6110/6108_6110.csv\n",
      "Loading /storage_1/metrics/Exp_6111/train/metrics_agent_metrics.csv for experiment 6111\n",
      "Loading /storage_1/metrics/Exp_6112/train/metrics_agent_metrics.csv for experiment 6112\n",
      "Loading /storage_1/metrics/Exp_6113/train/metrics_agent_metrics.csv for experiment 6113\n",
      "Data successfully saved to ./processed_data/6111_6113/6111_6113.csv\n",
      "Loading /storage_1/metrics/Exp_6114/train/metrics_agent_metrics.csv for experiment 6114\n",
      "Loading /storage_1/metrics/Exp_6115/train/metrics_agent_metrics.csv for experiment 6115\n",
      "Loading /storage_1/metrics/Exp_6116/train/metrics_agent_metrics.csv for experiment 6116\n",
      "Data successfully saved to ./processed_data/6114_6116/6114_6116.csv\n",
      "Loading /storage_1/metrics/Exp_6117/train/metrics_agent_metrics.csv for experiment 6117\n",
      "Loading /storage_1/metrics/Exp_6118/train/metrics_agent_metrics.csv for experiment 6118\n",
      "Loading /storage_1/metrics/Exp_6119/train/metrics_agent_metrics.csv for experiment 6119\n",
      "Data successfully saved to ./processed_data/6117_6119/6117_6119.csv\n",
      "Loading /storage_1/metrics/Exp_6120/train/metrics_agent_metrics.csv for experiment 6120\n",
      "Loading /storage_1/metrics/Exp_6121/train/metrics_agent_metrics.csv for experiment 6121\n",
      "Loading /storage_1/metrics/Exp_6122/train/metrics_agent_metrics.csv for experiment 6122\n",
      "Data successfully saved to ./processed_data/6120_6122/6120_6122.csv\n",
      "Loading /storage_1/metrics/Exp_6123/train/metrics_agent_metrics.csv for experiment 6123\n",
      "Loading /storage_1/metrics/Exp_6124/train/metrics_agent_metrics.csv for experiment 6124\n",
      "Loading /storage_1/metrics/Exp_6125/train/metrics_agent_metrics.csv for experiment 6125\n",
      "Data successfully saved to ./processed_data/6123_6125/6123_6125.csv\n",
      "Loading /storage_1/metrics/Exp_6126/train/metrics_agent_metrics.csv for experiment 6126\n",
      "Loading /storage_1/metrics/Exp_6127/train/metrics_agent_metrics.csv for experiment 6127\n",
      "Loading /storage_1/metrics/Exp_6128/train/metrics_agent_metrics.csv for experiment 6128\n",
      "Data successfully saved to ./processed_data/6126_6128/6126_6128.csv\n",
      "Loading /storage_1/metrics/Exp_6129/train/metrics_agent_metrics.csv for experiment 6129\n",
      "Loading /storage_1/metrics/Exp_6130/train/metrics_agent_metrics.csv for experiment 6130\n",
      "Loading /storage_1/metrics/Exp_6131/train/metrics_agent_metrics.csv for experiment 6131\n",
      "Data successfully saved to ./processed_data/6129_6131/6129_6131.csv\n",
      "Loading /storage_1/metrics/Exp_6132/train/metrics_agent_metrics.csv for experiment 6132\n",
      "Loading /storage_1/metrics/Exp_6133/train/metrics_agent_metrics.csv for experiment 6133\n",
      "Loading /storage_1/metrics/Exp_6134/train/metrics_agent_metrics.csv for experiment 6134\n",
      "Data successfully saved to ./processed_data/6132_6134/6132_6134.csv\n",
      "Loading /storage_1/metrics/Exp_6135/train/metrics_agent_metrics.csv for experiment 6135\n",
      "Loading /storage_1/metrics/Exp_6136/train/metrics_agent_metrics.csv for experiment 6136\n",
      "Loading /storage_1/metrics/Exp_6137/train/metrics_agent_metrics.csv for experiment 6137\n",
      "Data successfully saved to ./processed_data/6135_6137/6135_6137.csv\n",
      "Loading /storage_1/metrics/Exp_6138/train/metrics_agent_metrics.csv for experiment 6138\n",
      "Loading /storage_1/metrics/Exp_6139/train/metrics_agent_metrics.csv for experiment 6139\n",
      "Loading /storage_1/metrics/Exp_6140/train/metrics_agent_metrics.csv for experiment 6140\n",
      "Data successfully saved to ./processed_data/6138_6140/6138_6140.csv\n",
      "Loading /storage_1/metrics/Exp_6141/train/metrics_agent_metrics.csv for experiment 6141\n",
      "Loading /storage_1/metrics/Exp_6142/train/metrics_agent_metrics.csv for experiment 6142\n",
      "Loading /storage_1/metrics/Exp_6143/train/metrics_agent_metrics.csv for experiment 6143\n",
      "Data successfully saved to ./processed_data/6141_6143/6141_6143.csv\n",
      "Loading /storage_1/metrics/Exp_6144/train/metrics_agent_metrics.csv for experiment 6144\n",
      "Loading /storage_1/metrics/Exp_6145/train/metrics_agent_metrics.csv for experiment 6145\n",
      "Loading /storage_1/metrics/Exp_6146/train/metrics_agent_metrics.csv for experiment 6146\n",
      "Data successfully saved to ./processed_data/6144_6146/6144_6146.csv\n",
      "Loading /storage_1/metrics/Exp_6147/train/metrics_agent_metrics.csv for experiment 6147\n",
      "Loading /storage_1/metrics/Exp_6148/train/metrics_agent_metrics.csv for experiment 6148\n",
      "Loading /storage_1/metrics/Exp_6149/train/metrics_agent_metrics.csv for experiment 6149\n",
      "Data successfully saved to ./processed_data/6147_6149/6147_6149.csv\n",
      "Loading /storage_1/metrics/Exp_6150/train/metrics_agent_metrics.csv for experiment 6150\n",
      "Loading /storage_1/metrics/Exp_6151/train/metrics_agent_metrics.csv for experiment 6151\n",
      "Loading /storage_1/metrics/Exp_6152/train/metrics_agent_metrics.csv for experiment 6152\n",
      "Data successfully saved to ./processed_data/6150_6152/6150_6152.csv\n",
      "Loading /storage_1/metrics/Exp_6153/train/metrics_agent_metrics.csv for experiment 6153\n",
      "Loading /storage_1/metrics/Exp_6154/train/metrics_agent_metrics.csv for experiment 6154\n",
      "Loading /storage_1/metrics/Exp_6155/train/metrics_agent_metrics.csv for experiment 6155\n",
      "Data successfully saved to ./processed_data/6153_6155/6153_6155.csv\n",
      "Loading /storage_1/metrics/Exp_6156/train/metrics_agent_metrics.csv for experiment 6156\n",
      "Loading /storage_1/metrics/Exp_6157/train/metrics_agent_metrics.csv for experiment 6157\n",
      "Loading /storage_1/metrics/Exp_6158/train/metrics_agent_metrics.csv for experiment 6158\n",
      "Data successfully saved to ./processed_data/6156_6158/6156_6158.csv\n",
      "Loading /storage_1/metrics/Exp_6159/train/metrics_agent_metrics.csv for experiment 6159\n",
      "Loading /storage_1/metrics/Exp_6160/train/metrics_agent_metrics.csv for experiment 6160\n",
      "Loading /storage_1/metrics/Exp_6161/train/metrics_agent_metrics.csv for experiment 6161\n",
      "Data successfully saved to ./processed_data/6159_6161/6159_6161.csv\n",
      "Loading /storage_1/metrics/Exp_6162/train/metrics_agent_metrics.csv for experiment 6162\n",
      "Loading /storage_1/metrics/Exp_6163/train/metrics_agent_metrics.csv for experiment 6163\n",
      "Loading /storage_1/metrics/Exp_6164/train/metrics_agent_metrics.csv for experiment 6164\n",
      "Data successfully saved to ./processed_data/6162_6164/6162_6164.csv\n",
      "Loading /storage_1/metrics/Exp_6165/train/metrics_agent_metrics.csv for experiment 6165\n",
      "Loading /storage_1/metrics/Exp_6166/train/metrics_agent_metrics.csv for experiment 6166\n",
      "Loading /storage_1/metrics/Exp_6167/train/metrics_agent_metrics.csv for experiment 6167\n",
      "Data successfully saved to ./processed_data/6165_6167/6165_6167.csv\n",
      "Loading /storage_1/metrics/Exp_6168/train/metrics_agent_metrics.csv for experiment 6168\n",
      "Loading /storage_1/metrics/Exp_6169/train/metrics_agent_metrics.csv for experiment 6169\n",
      "Loading /storage_1/metrics/Exp_6170/train/metrics_agent_metrics.csv for experiment 6170\n",
      "Data successfully saved to ./processed_data/6168_6170/6168_6170.csv\n",
      "Loading /storage_1/metrics/Exp_6171/train/metrics_agent_metrics.csv for experiment 6171\n",
      "Loading /storage_1/metrics/Exp_6172/train/metrics_agent_metrics.csv for experiment 6172\n",
      "Loading /storage_1/metrics/Exp_6173/train/metrics_agent_metrics.csv for experiment 6173\n",
      "Data successfully saved to ./processed_data/6171_6173/6171_6173.csv\n",
      "Loading /storage_1/metrics/Exp_6174/train/metrics_agent_metrics.csv for experiment 6174\n",
      "Loading /storage_1/metrics/Exp_6175/train/metrics_agent_metrics.csv for experiment 6175\n",
      "Loading /storage_1/metrics/Exp_6176/train/metrics_agent_metrics.csv for experiment 6176\n",
      "Data successfully saved to ./processed_data/6174_6176/6174_6176.csv\n",
      "Loading /storage_1/metrics/Exp_6177/train/metrics_agent_metrics.csv for experiment 6177\n"
     ]
    }
   ],
   "source": [
    "# Define experiment range and chunk size\n",
    "starting_exp = 6108\n",
    "ending_exp = 6179\n",
    "chunk_size = 3\n",
    "\n",
    "all_experiments = list(range(starting_exp, ending_exp + 1))\n",
    "experiment_chunks = [all_experiments[i:i + chunk_size] for i in range(0, len(all_experiments), chunk_size)]\n",
    "save_processed_data = True\n",
    "file_path_for_processed_data = './processed_data'\n",
    "\n",
    "for chunk in experiment_chunks:\n",
    "    exp_agent_data = []\n",
    "    \n",
    "    for exp_num in chunk:\n",
    "        config_fname = f'./Exp_{exp_num}/config.yaml'\n",
    "        c = load_config_file(config_fname)\n",
    "        nn_c = c['nn_hyperparameters']\n",
    "        federated_c = c['federated_learning_settings']\n",
    "        algo_c = c['algorithm_settings']\n",
    "        env_c = c['environment_settings']\n",
    "        cma_c = c['cma_parameters']\n",
    "    \n",
    "        seed = env_c['seed']\n",
    "        algorithm_dm = algo_c['algorithm']\n",
    "\n",
    "        def load_from_json_with_error_handling(filepath, columns_specific):\n",
    "            try:\n",
    "                return read_csv_data(filepath, columns=columns_specific)\n",
    "            except json.JSONDecodeError as e:\n",
    "                print(f\"Error decoding JSON from {filepath}: {e.msg} at line {e.lineno}, column {e.colno}\")\n",
    "                return None\n",
    "    \n",
    "        path_list = [\n",
    "            f\"/storage_1/metrics/Exp_{exp_num}\"\n",
    "        ]\n",
    "    \n",
    "        d_base = next((p for p in path_list if os.path.exists(p)), None)\n",
    "        if d_base is None:\n",
    "            print(f\"Data folder not found for experiment {exp_num}; skipping.\")\n",
    "            continue\n",
    "\n",
    "        base_path = f\"{d_base}/train/metrics\"\n",
    "        print(f'Loading {base_path}_agent_metrics.csv for experiment {exp_num}')\n",
    "        agent_data = load_from_json_with_error_handling(\n",
    "            f'{base_path}_agent_metrics.csv',\n",
    "            ['episode', 'timestep', 'done', 'zone', 'aggregation', 'agent_index', 'reward']\n",
    "        )\n",
    "        if agent_data is None:\n",
    "            continue\n",
    "\n",
    "        agent_data['seed'] = seed\n",
    "        agent_data['exp_num'] = exp_num\n",
    "        agent_data['algorithm'] = algorithm_dm\n",
    "        agent_data['season'] = env_c['season']\n",
    "        agent_data['num_aggs'] = federated_c['aggregation_count']\n",
    "        agent_data['eps_per_agg'] = (\n",
    "            cma_c['max_generations'] if algorithm_dm == 'CMA' else nn_c['num_episodes']\n",
    "        )\n",
    "\n",
    "        exp_agent_data.append(agent_data)\n",
    "\n",
    "    if len(exp_agent_data) == 0:\n",
    "        continue\n",
    "\n",
    "    df_agent = pd.concat(exp_agent_data, ignore_index=True)\n",
    "\n",
    "    cumulative_agent_df = (\n",
    "        df_agent\n",
    "        .groupby(\n",
    "            ['episode', 'zone', 'aggregation', 'agent_index', 'seed', 'exp_num', 'algorithm', 'season', 'num_aggs', 'eps_per_agg']\n",
    "        )['reward']\n",
    "        .sum()\n",
    "        .reset_index()\n",
    "    )\n",
    "    cumulative_agent_df.rename(columns={'reward': 'cumulative_reward'}, inplace=True)\n",
    "    cumulative_agent_df['episode'] = (\n",
    "        cumulative_agent_df['aggregation'] * cumulative_agent_df['eps_per_agg'] + cumulative_agent_df['episode']\n",
    "    )\n",
    "\n",
    "    cumulative_avg_reward_by_algorithm = (\n",
    "        cumulative_agent_df\n",
    "        .groupby(['episode', 'algorithm', 'seed', 'num_aggs', 'season', 'eps_per_agg', 'exp_num'])['cumulative_reward']\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    cumulative_avg_reward_by_algorithm = cumulative_avg_reward_by_algorithm.sort_values(\n",
    "        ['season', 'algorithm', 'seed', 'num_aggs', 'episode']\n",
    "    )\n",
    "    cumulative_avg_reward_by_algorithm['cumulative_reward'] = (\n",
    "        cumulative_avg_reward_by_algorithm\n",
    "        .groupby(['algorithm', 'seed', 'num_aggs', 'season'])['cumulative_reward']\n",
    "        .transform(lambda x: x.expanding().mean())\n",
    "    )\n",
    "\n",
    "    if save_processed_data:\n",
    "        chunk_folder = os.path.join(file_path_for_processed_data, f\"{chunk[0]}_{chunk[-1]}\")\n",
    "        os.makedirs(chunk_folder, exist_ok=True)\n",
    "        csv_path = os.path.join(chunk_folder, f\"{chunk[0]}_{chunk[-1]}.csv\")\n",
    "        cumulative_avg_reward_by_algorithm.to_csv(csv_path, index=False)\n",
    "        print(f\"Data successfully saved to {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d7477d-38b0-416d-9357-91159938a871",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for chunk in experiment_chunks:\n",
    "    chunk_file = os.path.join(file_path_for_processed_data, f\"{chunk[0]}_{chunk[-1]}\", f\"{chunk[0]}_{chunk[-1]}.csv\")\n",
    "    if not os.path.exists(chunk_file):\n",
    "        print(f\"Missing file for chunk {chunk[0]}–{chunk[-1]}; skipping plot.\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(chunk_file)\n",
    "    print(df.head())\n",
    "    print(df.tail()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125150cd-4a04-4526-b22a-575c26812abe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for chunk in experiment_chunks:\n",
    "    chunk_file = os.path.join(file_path_for_processed_data, f\"{chunk[0]}_{chunk[-1]}\", f\"{chunk[0]}_{chunk[-1]}.csv\")\n",
    "    if not os.path.exists(chunk_file):\n",
    "        print(f\"Missing file for chunk {chunk[0]}–{chunk[-1]}; skipping plot.\")\n",
    "        continue\n",
    "\n",
    "    df = pd.read_csv(chunk_file)\n",
    "\n",
    "    # Check for mixed seasons (fall back to 'Mixed' if more than one unique value)\n",
    "    unique_seasons = df['season'].unique()\n",
    "    season_label = unique_seasons[0] if len(unique_seasons) == 1 else \"Mixed\"\n",
    "\n",
    "    agg_data = (\n",
    "        df\n",
    "        .groupby(['episode', 'algorithm'])['cumulative_reward']\n",
    "        .agg(['mean', 'min', 'max'])\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "    for algo in agg_data['algorithm'].unique():\n",
    "        algo_data = agg_data[agg_data['algorithm'] == algo]\n",
    "        ax.fill_between(\n",
    "            algo_data['episode'],\n",
    "            algo_data['min'],\n",
    "            algo_data['max'],\n",
    "            color=colors.get(algo, 'gray'),\n",
    "            alpha=0.3\n",
    "        )\n",
    "        ax.plot(\n",
    "            algo_data['episode'],\n",
    "            algo_data['mean'],\n",
    "            color=colors.get(algo, 'gray'),\n",
    "            label=f'{algo} Average Reward'\n",
    "        )\n",
    "\n",
    "    # Estimate eps_per_agg if needed\n",
    "    if 'eps_per_agg' in df.columns:\n",
    "        eps_per_agg = df['eps_per_agg'].iloc[0]\n",
    "    else:\n",
    "        num_aggs = df['num_aggs'].iloc[0]\n",
    "        max_episode = df['episode'].max()\n",
    "        eps_per_agg = int(np.ceil(max_episode / num_aggs))\n",
    "\n",
    "    num_aggs = df['num_aggs'].iloc[0]\n",
    "    for agg in range(1, int(num_aggs) + 1):\n",
    "        ax.axvline(x=agg * eps_per_agg, color='r', linestyle='--', linewidth=1, alpha=0.7)\n",
    "\n",
    "    # Add season label in top-left corner\n",
    "    x_pos = df['episode'].min()\n",
    "    y_pos = df['cumulative_reward'].max() * 0.95\n",
    "    ax.text(x_pos + 20, y_pos, f\"Season: {season_label}\", fontsize=12, bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "    ax.set_xlabel('Episode')\n",
    "    ax.set_ylabel('Cumulative Average Reward')\n",
    "    ax.set_title(f'Experiments {chunk[0]}–{chunk[-1]}')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    ax.set_xlim(0, 15000)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0afecb7-63d3-48c1-87b0-2d51ad61da10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "missing_chunks = []\n",
    "under_threshold_experiments = []\n",
    "\n",
    "for chunk in experiment_chunks:\n",
    "    chunk_file = os.path.join(\n",
    "        file_path_for_processed_data,\n",
    "        f\"{chunk[0]}_{chunk[-1]}\",\n",
    "        f\"{chunk[0]}_{chunk[-1]}.csv\"\n",
    "    )\n",
    "    if not os.path.exists(chunk_file):\n",
    "        missing_chunks.append(f\"{chunk[0]}–{chunk[-1]}\")\n",
    "        continue\n",
    "\n",
    "    df_chunk = pd.read_csv(chunk_file)\n",
    "\n",
    "    for exp_num in df_chunk['exp_num'].unique():\n",
    "        df = df_chunk[df_chunk['exp_num'] == exp_num]\n",
    "        max_episode = df['episode'].max()\n",
    "\n",
    "        # If an experiment has fewer than 3 900 episodes, record and skip plotting\n",
    "        if max_episode < 3900:\n",
    "            under_threshold_experiments.append((exp_num, max_episode))\n",
    "            continue\n",
    "\n",
    "        # … otherwise do your plotting as before …\n",
    "        unique_seasons = df['season'].unique()\n",
    "        season_label = unique_seasons[0] if len(unique_seasons) == 1 else \"Mixed\"\n",
    "\n",
    "        agg_data = (\n",
    "            df\n",
    "            .groupby(['episode', 'algorithm'])['cumulative_reward']\n",
    "            .agg(['mean', 'min', 'max'])\n",
    "            .reset_index()\n",
    "        )\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(10, 6))\n",
    "        for algo in agg_data['algorithm'].unique():\n",
    "            algo_data = agg_data[agg_data['algorithm'] == algo]\n",
    "            ax.fill_between(\n",
    "                algo_data['episode'],\n",
    "                algo_data['min'],\n",
    "                algo_data['max'],\n",
    "                color=colors.get(algo, 'gray'),\n",
    "                alpha=0.3\n",
    "            )\n",
    "            ax.plot(\n",
    "                algo_data['episode'],\n",
    "                algo_data['mean'],\n",
    "                color=colors.get(algo, 'gray'),\n",
    "                label=f'{algo} Average Reward'\n",
    "            )\n",
    "\n",
    "        eps_per_agg = (\n",
    "            df['eps_per_agg'].iloc[0]\n",
    "            if 'eps_per_agg' in df.columns\n",
    "            else int(np.ceil(df['episode'].max() / df['num_aggs'].iloc[0]))\n",
    "        )\n",
    "        for agg in range(1, int(df['num_aggs'].iloc[0]) + 1):\n",
    "            ax.axvline(\n",
    "                x=agg * eps_per_agg,\n",
    "                color='r',\n",
    "                linestyle='--',\n",
    "                linewidth=1,\n",
    "                alpha=0.7\n",
    "            )\n",
    "\n",
    "        ax.text(\n",
    "            20,\n",
    "            df['cumulative_reward'].max() * 0.95,\n",
    "            f\"Season: {season_label}\",\n",
    "            fontsize=12,\n",
    "            bbox=dict(facecolor='white', alpha=0.5)\n",
    "        )\n",
    "        ax.set_xlabel('Episode')\n",
    "        ax.set_ylabel('Cumulative Average Reward')\n",
    "        ax.set_title(f'Experiment {exp_num}:')\n",
    "        ax.legend()\n",
    "        ax.grid(True)\n",
    "        ax.set_xlim(0, 10000)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# After all chunks are processed, print summaries:\n",
    "if missing_chunks:\n",
    "    print(\"\\nMissing files for these chunks (skipped entirely):\")\n",
    "    for rng in missing_chunks:\n",
    "        print(f\"  • {rng}\")\n",
    "\n",
    "if under_threshold_experiments:\n",
    "    print(\"\\nExperiments with fewer than 3 900 episodes (no plots generated):\")\n",
    "    for exp_num, max_ep in under_threshold_experiments:\n",
    "        print(f\"  • Experiment {exp_num}: only {max_ep} episodes\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
