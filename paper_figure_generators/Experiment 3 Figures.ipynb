{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d5bdbcd",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45773e86-ab4f-42f0-b5c2-eb9893e550ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "import itertools\n",
    "from environment.evaluation import *\n",
    "from environment.data_loader import *\n",
    "import random\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafebf72",
   "metadata": {},
   "source": [
    "### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05f179a2-7dd0-4b64-a41b-36d53d61dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\n",
    "    \"DQN\": 'darkorange',\n",
    "    \"REINFORCE\": 'forestgreen',\n",
    "    \"ODT\": 'blueviolet',\n",
    "}\n",
    "\n",
    "season_colors = {\n",
    "    \"winter\": 'blue',\n",
    "    \"spring\": 'forestgreen',\n",
    "    \"summer\": 'gold',\n",
    "    \"autumn\": 'darkorange'\n",
    "}\n",
    "\n",
    "experiments = list(itertools.chain(\n",
    "    range(4000, 4180),\n",
    "    range(5000, 5180),\n",
    "    range(6000, 6180),\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abfd38a",
   "metadata": {},
   "source": [
    "## Figure 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d6519c",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecde91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_agg_count = 10\n",
    "\n",
    "exp_power_data = []\n",
    "\n",
    "for ind, exp_num in enumerate(experiments):\n",
    "    config_fname = f'../experiments/Exp_{exp_num}/config.yaml'\n",
    "    \n",
    "    c = load_config_file(config_fname)\n",
    "    nn_c = c['nn_hyperparameters']\n",
    "    federated_c = c['federated_learning_settings']\n",
    "    algo_c = c['algorithm_settings']\n",
    "\n",
    "    if algo_c == 'ODT':\n",
    "        target_agg_count = 4\n",
    "    \n",
    "    env_c = c['environment_settings']\n",
    "    eval_c = c['eval_config']\n",
    "    \n",
    "    ev_info = []\n",
    "\n",
    "    seed = env_c['seed']\n",
    "\n",
    "    algorithm_dm = algo_c['algorithm']\n",
    "    \n",
    "    def load_from_json_with_error_handling(filepath, columns_specific):\n",
    "        try:\n",
    "            return read_csv_data(filepath, columns=columns_specific)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding JSON from {filepath}: {e.msg} at line {e.lineno}, column {e.colno}\")\n",
    "            return None  # Handle the error and return None or an empty object\n",
    "    \n",
    "    \n",
    "    d_base = f\"../../../../storage_1/metrics/Exp_{exp_num}\"\n",
    "    \n",
    "    if not os.path.exists(d_base):\n",
    "        d_base = f\"../metrics/Exp_{exp_num}\"\n",
    "            \n",
    "    base_path = f\"{d_base}/train/\"\n",
    "\n",
    "    print(f'Loading {base_path}power_and_co2_metrics.csv')\n",
    "    power_data = load_from_json_with_error_handling(f'{base_path}power_and_co2_metrics.csv', ['time', 'power', 'co2'])\n",
    "\n",
    "    power_data['seed'] = seed\n",
    "    power_data['exp_num'] = exp_num\n",
    "    \n",
    "    power_data['algorithm'] = algorithm_dm\n",
    "    power_data['season'] = env_c['season']\n",
    "    power_data['num_aggs'] = federated_c['aggregation_count']\n",
    "    power_data['eps_per_agg'] = nn_c['num_episodes']\n",
    "\n",
    "    exp_power_data.append(power_data)\n",
    "\n",
    "# Convert data to DataFrame for easier manipulation\n",
    "df_power = pd.concat(exp_power_data, ignore_index=True)\n",
    "\n",
    "# REMOVE CMA temp\n",
    "df_power = df_power[df_power['algorithm'] != 'CMA']\n",
    "\n",
    "df_power['cumulative_power'] = df_power.groupby('exp_num')['power'].cumsum()\n",
    "\n",
    "df_power['time'] = pd.to_datetime(df_power['time'], errors='coerce')\n",
    "df_power['time'] = df_power.groupby('exp_num')['time'].transform(lambda x: (x - x.min()).dt.total_seconds())\n",
    "\n",
    "df_power['co2'] = df_power['co2'] * 1000 # Convert to grams\n",
    "\n",
    "# Convert 3 aggs to 1 for CMA\n",
    "df_power['num_aggs'] = np.where(\n",
    "    (df_power['num_aggs'] == 3) & \n",
    "    (df_power['algorithm'] == 'CMA'), \n",
    "    1, \n",
    "    df_power['num_aggs']\n",
    ")\n",
    "\n",
    "final_times = df_power.groupby('exp_num')['time'].max().reset_index()\n",
    "final_times.rename(columns={'time': 'final_time'}, inplace=True)\n",
    "\n",
    "final_times = final_times.merge(df_power[['exp_num', 'num_aggs']].drop_duplicates(), on='exp_num')\n",
    "\n",
    "average_final_time = final_times.groupby('num_aggs')['final_time'].mean().reset_index()\n",
    "\n",
    "average_final_time['agg_label'] = average_final_time['num_aggs'].apply(lambda x: f\"{x} Aggregations\")\n",
    "\n",
    "def seconds_to_hms(seconds):\n",
    "    hours = seconds // 3600\n",
    "    minutes = (seconds % 3600) // 60\n",
    "    secs = seconds % 60\n",
    "    return f\"{int(hours):02}:{int(minutes):02}:{int(secs):02}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b185b040",
   "metadata": {},
   "source": [
    "### Displaying figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3780e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure output directory exists\n",
    "os.makedirs(\"Figures\", exist_ok=True)\n",
    "\n",
    "# 1) Prepare finals DataFrame\n",
    "df_10 = df_power[(df_power.num_aggs == 10) & (df_power.exp_num != 4129)].copy()\n",
    "finals = (\n",
    "    df_10\n",
    "    .sort_values(\"time\")\n",
    "    .groupby([\"algorithm\", \"exp_num\"], as_index=False)\n",
    "    .last()[[\"algorithm\", \"exp_num\", \"time\", \"cumulative_power\"]]\n",
    ")\n",
    "finals[\"hours\"] = finals[\"time\"] / 3600.0\n",
    "finals[\"cum_kW\"] = finals[\"cumulative_power\"] / 1000.0\n",
    "\n",
    "# 2) Add DQN “pre-run” onto ODT runs\n",
    "mean_dqn_time = finals.loc[finals['algorithm'] == 'DQN', 'hours'].mean()\n",
    "mean_reinforce_time = finals.loc[finals['algorithm'] == 'REINFORCE', 'hours'].mean()\n",
    "\n",
    "mean_dqn_kw = finals.loc[finals['algorithm'] == 'DQN', 'cum_kW'].mean()\n",
    "mean_reinforce_kw = finals.loc[finals['algorithm'] == 'REINFORCE', 'cum_kW'].mean()\n",
    "\n",
    "print(mean_dqn_time)\n",
    "print(mean_reinforce_time)\n",
    "\n",
    "def add_to_odt(row):\n",
    "    if row.algorithm == \"ODT\":\n",
    "        # get the trailing number (last 3 digits) of exp_num\n",
    "        exp_str = str(row.exp_num)\n",
    "        try:\n",
    "            suffix = int(exp_str[-3:])\n",
    "        except ValueError:\n",
    "            # if it can’t be parsed, treat as “not in DQN range”\n",
    "            suffix = None\n",
    "\n",
    "        # if the suffix is between 108 and 144 inclusive, use DQN time\n",
    "        if suffix is not None and 108 <= suffix <= 144:\n",
    "            row.hours   += mean_dqn_time\n",
    "            row.cum_kW  += mean_dqn_kw\n",
    "        else:\n",
    "            row.hours   += mean_reinforce_time\n",
    "            row.cum_kW  += mean_reinforce_kw\n",
    "\n",
    "    return row\n",
    "\n",
    "    \n",
    "finals = finals.apply(add_to_odt, axis=1)\n",
    "\n",
    "# 3) Theme & palette\n",
    "sns.set_theme(style=\"white\")\n",
    "palette = sns.cubehelix_palette(finals.algorithm.nunique(), rot=-.25, light=.7)\n",
    "\n",
    "# 4) Plot ridgelines side-by-side\n",
    "algos = finals.algorithm.unique()\n",
    "n = len(algos)\n",
    "fig, axes = plt.subplots(n, 2, figsize=(6, n * 0.65), sharex='col')\n",
    "\n",
    "cum_min, cum_max = finals[\"cum_kW\"].min(), finals[\"cum_kW\"].max()\n",
    "hr_min, hr_max   = finals[\"hours\"].min(), finals[\"hours\"].max()\n",
    "\n",
    "for i, algo in enumerate(algos):\n",
    "    data, color = finals[finals.algorithm == algo], palette[i]\n",
    "\n",
    "    # ── LEFT column: cumulative power ────────────────────\n",
    "    ax = axes[i, 0]\n",
    "    sns.kdeplot(data.cum_kW, bw_adjust=0.5, fill=True, alpha=0.7,\n",
    "                linewidth=1.5, common_norm=False, ax=ax, color=colors[algo])\n",
    "    ax.set_xlim(cum_min, cum_max)\n",
    "    ax.set_ylabel(\"\")        # clear any old label\n",
    "    ax.set_yticks([])\n",
    "    ax.tick_params(left=False)\n",
    "\n",
    "    # full-width thick baseline\n",
    "    ax.axhline(0, color='black', linewidth=2, zorder=5)\n",
    "\n",
    "    # x-ticks only on bottom row\n",
    "    if i < n-1:\n",
    "        ax.tick_params(axis='x', bottom=False, labelbottom=False)\n",
    "    else:\n",
    "        ax.set_xlabel(\"Cumulative Power (kW)\", labelpad=10)\n",
    "        xt = np.unique(np.concatenate(([0], ax.get_xticks())))\n",
    "        ax.set_xticks(xt)\n",
    "        ax.tick_params(axis='x', pad=6)\n",
    "\n",
    "    # **new**: put algo name outside on the left\n",
    "    ax.set_ylabel(algo,\n",
    "                  rotation=0,\n",
    "                  ha='right',\n",
    "                  va='center',\n",
    "                  labelpad=10,\n",
    "                  color=colors[algo],\n",
    "                  fontweight='bold')\n",
    "\n",
    "    # hide unwanted spines\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(True)\n",
    "    ax.spines['left'].set_linewidth(1)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "\n",
    "    # ── RIGHT column: run time ────────────────────\n",
    "    ax = axes[i, 1]\n",
    "    \n",
    "    sns.kdeplot(data.hours, bw_adjust=0.5, fill=True, alpha=0.7,\n",
    "                linewidth=1.5, common_norm=False, ax=ax, color=colors[algo])\n",
    "    ax.set_xlim(hr_min, hr_max)\n",
    "    ax.set_ylabel(\"\"); ax.set_yticks([]); ax.tick_params(left=False)\n",
    "    ax.axhline(0, color='black', linewidth=2, zorder=5)\n",
    "\n",
    "    if i < n-1:\n",
    "        ax.tick_params(axis='x', bottom=False, labelbottom=False)\n",
    "    else:\n",
    "        ax.set_xlabel(\"Time (hours)\", labelpad=10)\n",
    "        xt = np.unique(np.concatenate(([0], ax.get_xticks())))\n",
    "        ax.set_xticks(xt)\n",
    "        ax.tick_params(axis='x', pad=6)\n",
    "\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(True)\n",
    "    ax.spines['left'].set_linewidth(1)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "\n",
    "# overall layout\n",
    "fig.subplots_adjust(\n",
    "    top=0.90,\n",
    "    bottom=0.05,\n",
    "    left=0.15,   # ← more room for the outside labels\n",
    "    right=0.98,\n",
    "    hspace=0.0,\n",
    "    wspace=0.3,\n",
    ")\n",
    "\n",
    "# save & show\n",
    "out_path = os.path.join(\"Figures\", \"ridgeline_nocma.png\")\n",
    "fig.savefig(out_path, dpi=150, bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95109f80",
   "metadata": {},
   "source": [
    "## Table 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35214964",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0798e9ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11e00d42",
   "metadata": {},
   "source": [
    "### Printing data for table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5ea742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate energy in kWh for a single experiment\n",
    "def calculate_energy_kWh(exp_data):\n",
    "    # Sort the data by elapsed time\n",
    "    exp_data_sorted = exp_data.sort_values('time')\n",
    "    \n",
    "    # Extract power (W) and time (s)\n",
    "    power = exp_data_sorted['power'].values  # Power in W\n",
    "    time_sec = exp_data_sorted['time'].values  # Time in seconds\n",
    "    \n",
    "    # Convert time to hours for integration\n",
    "    time_hours = time_sec / 3600  # Convert seconds to hours\n",
    "    \n",
    "    # Handle cases where time_hours may not be strictly increasing\n",
    "    # Ensure that time_hours is sorted and unique\n",
    "    if not np.all(np.diff(time_hours) >= 0):\n",
    "        raise ValueError(\"Time data must be sorted and non-decreasing for integration.\")\n",
    "    \n",
    "    # Integrate power over time using the trapezoidal rule to get energy in Wh\n",
    "    energy_Wh = np.trapz(power, time_hours)  # Integration: ∫ P(t) dt\n",
    "    \n",
    "    # Convert Wh to kWh\n",
    "    energy_kWh = energy_Wh / 1000\n",
    "    \n",
    "    return energy_kWh\n",
    "\n",
    "results = []\n",
    "\n",
    "finals['adj_hours'] = finals['hours']\n",
    "\n",
    "# group by algorithm and compute mean & standard deviation\n",
    "stats = (\n",
    "    finals\n",
    "    .groupby('algorithm')['adj_hours']\n",
    "    .agg(['mean','std', 'min', 'max'])\n",
    "    .rename(columns={'mean':'avg_hours','std':'std_hours', 'min': 'min_hours', 'max': 'max_hours'})\n",
    ")\n",
    "\n",
    "duration_results = {\"DQN\": {}, \"REINFORCE\": {}, \"ODT\": {}}\n",
    "\n",
    "print(\"Algorithm    Mean (h)    Std Dev (h)    Min (h)    Max (h)\")\n",
    "\n",
    "for algo, row in stats.iterrows():\n",
    "    duration_results[algo] = {\n",
    "        \"Mean (h)\": row.avg_hours,\n",
    "        \"Std Dev (h)\": row.std_hours\n",
    "    }\n",
    "\n",
    "    print(f\"{algo: <12}{row.avg_hours:>8.3f}{row.std_hours:>12.3f}{row.min_hours:>12.3f}{row.max_hours:>12.3f}\")\n",
    "\n",
    "# Iterate over each unique algorithm in the DataFrame\n",
    "for algo in df_power['algorithm'].unique():\n",
    "    # Filter data for the current algorithm\n",
    "    algo_data = df_power[df_power['algorithm'] == algo]\n",
    "    \n",
    "    # Group by 'exp_num' to process each experiment separately\n",
    "    grouped = algo_data.groupby('exp_num')\n",
    "    \n",
    "    # Initialize lists to store energy and CO2 for each experiment\n",
    "    energy_kWh_list = []\n",
    "    co2_list = []\n",
    "    \n",
    "    # Iterate over each experiment within the algorithm\n",
    "    for exp_num, exp_data in grouped:\n",
    "        try:\n",
    "            # Calculate energy in kWh for the experiment\n",
    "            energy_kWh = calculate_energy_kWh(exp_data)\n",
    "            energy_kWh_list.append(energy_kWh)\n",
    "            \n",
    "            # Assume 'co2' is recorded at each time point; take the last entry as total CO2\n",
    "            co2_total = exp_data['co2'].iloc[-1]\n",
    "            co2_list.append(co2_total)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing Algorithm {algo}, Experiment {exp_num}: {e}\")\n",
    "    \n",
    "    # Convert lists to NumPy arrays for statistical calculations\n",
    "    energy_kWh_array = np.array(energy_kWh_list)\n",
    "    co2_array = np.array(co2_list)\n",
    "    \n",
    "    # Calculate mean and standard deviation for energy\n",
    "    avg_energy_kWh = energy_kWh_array.mean()\n",
    "    std_energy_kWh = energy_kWh_array.std()\n",
    "    \n",
    "    # Calculate mean and standard deviation for CO2 emissions\n",
    "    avg_co2 = co2_array.mean()\n",
    "    std_co2 = co2_array.std()\n",
    "    \n",
    "    # Print the metrics with updated units\n",
    "    print(f\"Algorithm {algo} Power and CO2 Metrics\")\n",
    "    print(f\"\\tAverage energy used per experiment: {avg_energy_kWh:.4f} kWh\")\n",
    "    print(f\"\\tStandard deviation of energy used per experiment: {std_energy_kWh:.4f} kWh\")\n",
    "    print(f\"\\tAverage CO2 estimated emissions per experiment: {avg_co2:.4f} g\")\n",
    "    print(f\"\\tStandard deviation of CO2 estimated emissions per experiment: {std_co2:.4f} g\\n\")\n",
    "\n",
    "    results.append([algo, duration_results[algo][\"Mean (h)\"], duration_results[algo][\"Std Dev (h)\"], avg_energy_kWh, std_energy_kWh, avg_co2, std_co2])\n",
    "\n",
    "results_df = pd.DataFrame(results, columns=[\"Algorithm\", \"Mean (h)\", \"Std Dev (h)\", \"Avg Energy Used (kWh)\", \"Std Energy Used (kWh)\", \"Avg CO2 (g)\", \"Std CO2 (g)\"])\n",
    "\n",
    "results_df.to_csv('./table_data/table_2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
